diff -Naur ofa_kernel-1.4/drivers/infiniband/hw/ipath/Makefile ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/Makefile
--- ofa_kernel-1.4/drivers/infiniband/hw/ipath/Makefile	2008-10-30 16:33:49.000000000 -0700
+++ ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/Makefile	2008-11-03 11:25:38.000022000 -0800
@@ -37,5 +37,6 @@
 ib_ipath-y += ipath_iba6110.o
 ib_ipath-$(CONFIG_PCI_MSI) += ipath_iba6120.o
 
+ib_ipath-$(CONFIG_X86_64) += memcpy_cachebypass_x86_64.o
 ib_ipath-$(CONFIG_X86_64) += ipath_wc_x86_64.o
 ib_ipath-$(CONFIG_PPC64) += ipath_wc_ppc64.o
diff -Naur ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_rc.c ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_rc.c
--- ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_rc.c	2008-10-19 05:15:07.000000000 -0700
+++ ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_rc.c	2008-11-03 11:32:01.000014000 -0800
@@ -48,6 +48,7 @@
 	ss->sge = wqe->sg_list[0];
 	ss->sg_list = wqe->sg_list + 1;
 	ss->num_sge = wqe->wr.num_sge;
+	ss->total_len = wqe->length;
 	ipath_skip_sge(ss, len);
 	return wqe->length - len;
 }
@@ -461,6 +462,7 @@
 		qp->s_sge.sge = wqe->sg_list[0];
 		qp->s_sge.sg_list = wqe->sg_list + 1;
 		qp->s_sge.num_sge = wqe->wr.num_sge;
+		qp->s_sge.total_len = wqe->length;
 		qp->s_len = wqe->length;
 		if (newreq) {
 			qp->s_tail++;
diff -Naur ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_ruc.c ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_ruc.c
--- ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_ruc.c	2008-10-19 05:15:07.000000000 -0700
+++ ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_ruc.c	2008-11-03 11:38:47.001577000 -0800
@@ -137,6 +137,7 @@
 		j++;
 	}
 	ss->num_sge = j;
+	ss->total_len = *lengthp;
 	ret = 1;
 	goto bail;
 
@@ -356,6 +357,7 @@
 					    wqe->wr.wr.rdma.rkey,
 					    IB_ACCESS_REMOTE_WRITE)))
 			goto acc_err;
+		qp->r_sge.total_len = wqe->length;
 		break;
 
 	case IB_WR_RDMA_READ:
@@ -369,6 +371,7 @@
 		qp->r_sge.sge = wqe->sg_list[0];
 		qp->r_sge.sg_list = wqe->sg_list + 1;
 		qp->r_sge.num_sge = wqe->wr.num_sge;
+		qp->r_sge.total_len = wqe->length;
 		break;
 
 	case IB_WR_ATOMIC_CMP_AND_SWP:
diff -Naur ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_uc.c ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_uc.c
--- ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_uc.c	2008-10-19 05:15:07.000000000 -0700
+++ ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_uc.c	2008-11-03 11:39:34.000010000 -0800
@@ -98,6 +98,7 @@
 		qp->s_sge.sge = wqe->sg_list[0];
 		qp->s_sge.sg_list = wqe->sg_list + 1;
 		qp->s_sge.num_sge = wqe->wr.num_sge;
+		qp->s_sge.total_len = wqe->length;
 		qp->s_len = len = wqe->length;
 		switch (wqe->wr.opcode) {
 		case IB_WR_SEND:
diff -Naur ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_ud.c ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_ud.c
--- ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_ud.c	2008-10-19 05:15:07.000000000 -0700
+++ ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_ud.c	2008-11-03 11:40:00.000010000 -0800
@@ -339,6 +339,7 @@
 	qp->s_sge.sge = wqe->sg_list[0];
 	qp->s_sge.sg_list = wqe->sg_list + 1;
 	qp->s_sge.num_sge = wqe->wr.num_sge;
+	qp->s_sge.total_len = wqe->length;
 
 	if (ah_attr->ah_flags & IB_AH_GRH) {
 		/* Header size in 32-bit words. */
diff -Naur ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_verbs.c ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_verbs.c
--- ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_verbs.c	2008-10-30 16:33:49.000000000 -0700
+++ ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_verbs.c	2008-11-03 11:27:30.000015000 -0800
@@ -41,6 +41,14 @@
 #include "ipath_verbs.h"
 #include "ipath_common.h"
 
+#ifdef __x86_64__
+void *memcpy_cachebypass(void *, const void *, __kernel_size_t);
+void *memcpy_cachebypass2(void *, const void *, __kernel_size_t);
+#else
+#define memcpy_cachebypass(a,b,c) memcpy((a),(b),(c))
+#define memcpy_cachebypass2(a,b,c) memcpy((a),(b),(c))
+#endif
+
 static unsigned int ib_ipath_qp_table_size = 251;
 module_param_named(qp_table_size, ib_ipath_qp_table_size, uint, S_IRUGO);
 MODULE_PARM_DESC(qp_table_size, "QP table size");
@@ -178,7 +186,10 @@
 		if (len > sge->sge_length)
 			len = sge->sge_length;
 		BUG_ON(len == 0);
-		memcpy(sge->vaddr, data, len);
+		if (ss->total_len > 512 * 1024)
+			memcpy_cachebypass2(sge->vaddr, data, len);
+		else
+			memcpy_cachebypass(sge->vaddr, data, len);
 		sge->vaddr += len;
 		sge->length -= len;
 		sge->sge_length -= len;
diff -Naur ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_verbs.h ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_verbs.h
--- ofa_kernel-1.4/drivers/infiniband/hw/ipath/ipath_verbs.h	2008-10-19 05:15:07.000000000 -0700
+++ ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/ipath_verbs.h	2008-11-03 11:30:35.000011000 -0800
@@ -328,6 +328,7 @@
 struct ipath_sge_state {
 	struct ipath_sge *sg_list;      /* next SGE to be used if any */
 	struct ipath_sge sge;   /* progress state for the current SGE */
+	u32 total_len;
 	u8 num_sge;
 	u8 static_rate;
 };
diff -Naur ofa_kernel-1.4/drivers/infiniband/hw/ipath/memcpy_cachebypass_x86_64.S ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/memcpy_cachebypass_x86_64.S
--- ofa_kernel-1.4/drivers/infiniband/hw/ipath/memcpy_cachebypass_x86_64.S	1969-12-31 16:00:00.000000000 -0800
+++ ofa_kernel-1.4-memcpy_cachebypass/drivers/infiniband/hw/ipath/memcpy_cachebypass_x86_64.S	2008-11-03 11:24:28.000354000 -0800
@@ -0,0 +1,266 @@
+/*
+ * Copyright (c) 2006, 2007 QLogic Corporation. All rights reserved.
+ * Copyright (c) 2003, 2004, 2005, 2006 PathScale, Inc. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+	.text
+	.p2align 4,,15
+	/* rdi  destination, rsi source, rdx count */
+	.globl	memcpy_cachebypass
+	.type	memcpy_cachebypass, @function
+# loads bypass the cache, stores fill the cache
+memcpy_cachebypass:
+	movq	%rdi, %rax
+.L5:
+	cmpq	$15, %rdx
+	ja	.L34
+.L3:
+	cmpl	$8, %edx	/* rdx is 0..15 */
+	jbe	.L9
+.L6:
+	testb	$8, %dxl	/* rdx is 3,5,6,7,9..15 */
+	je	.L13
+	movq	(%rsi), %rcx
+	addq	$8, %rsi
+	movq	%rcx, (%rdi)
+	addq	$8, %rdi
+.L13:
+	testb	$4, %dxl
+	je	.L15
+	movl	(%rsi), %ecx
+	addq	$4, %rsi
+	movl	%ecx, (%rdi)
+	addq	$4, %rdi
+.L15:
+	testb	$2, %dxl
+	je	.L17
+	movzwl	(%rsi), %ecx
+	addq	$2, %rsi
+	movw	%cx, (%rdi)
+	addq	$2, %rdi
+.L17:
+	testb	$1, %dxl
+	je	.L33
+.L1:
+	movzbl	(%rsi), %ecx
+	movb	%cl, (%rdi)
+.L33:
+	ret
+.L34:
+	cmpq	$63, %rdx	/* rdx is > 15 */
+	ja	.L64
+	movl	$16, %ecx	/* rdx is 16..63 */
+.L25:
+	movq	8(%rsi), %r8
+	movq	(%rsi), %r9
+	addq	%rcx, %rsi
+	movq	%r8, 8(%rdi)
+	movq	%r9, (%rdi)
+	addq	%rcx, %rdi
+	subq	%rcx, %rdx
+	cmpl	%edx, %ecx	/* is rdx >= 16? */
+	jbe	.L25
+	jmp	.L3		/* rdx is 0..15 */
+	.p2align 4,,7
+.L64:
+	movl	$64, %ecx
+.L42:
+	prefetchnta	256(%rsi)
+	movq	(%rsi), %r8
+	movq	8(%rsi), %r9
+	movq	16(%rsi), %r10
+	movq	24(%rsi), %r11
+	subq	%rcx, %rdx
+	movq	%r8, (%rdi)
+	movq	32(%rsi), %r8
+	movq	%r9, 8(%rdi)
+	movq	40(%rsi), %r9
+	movq	%r10, 16(%rdi)
+	movq	48(%rsi), %r10
+	movq	%r11, 24(%rdi)
+	movq	56(%rsi), %r11
+	addq	%rcx, %rsi
+	movq	%r8, 32(%rdi)
+	movq	%r9, 40(%rdi)
+	movq	%r10, 48(%rdi)
+	movq	%r11, 56(%rdi)
+	addq	%rcx, %rdi
+	cmpq	%rdx, %rcx	/* is rdx >= 64? */
+	jbe	.L42
+	sfence
+	orl	%edx, %edx
+	je	.L33
+	jmp	.L5
+.L9:
+	jmp	*.L12(,%rdx,8)	/* rdx is 0..8 */
+	.section	.rodata
+	.align 8
+	.align 4
+.L12:
+	.quad	.L33
+	.quad	.L1
+	.quad	.L2
+	.quad	.L6
+	.quad	.L4
+	.quad	.L6
+	.quad	.L6
+	.quad	.L6
+	.quad	.L8
+	.text
+.L2:
+	movzwl	(%rsi), %ecx
+	movw	%cx, (%rdi)
+	ret
+.L4:
+	movl	(%rsi), %ecx
+	movl	%ecx, (%rdi)
+	ret
+.L8:
+	movq	(%rsi), %rcx
+	movq	%rcx, (%rdi)
+	ret
+
+		.text
+	.p2align 4,,15
+	/* rdi  destination, rsi source, rdx count */
+	.globl	memcpy_cachebypass2
+	.type	memcpy_cachebypass2, @function
+# both loads and stores bypass the cache
+memcpy_cachebypass2:
+	movq	%rdi, %rax
+.L2_5:
+	cmpq	$15, %rdx
+	ja	.L2_34
+.L2_3:
+	cmpl	$8, %edx	/* rdx is 0..15 */
+	jbe	.L2_9
+.L2_6:
+	testb	$8, %dxl	/* rdx is 3,5,6,7,9..15 */
+	je	.L2_13
+	movq	(%rsi), %rcx
+	addq	$8, %rsi
+	movq	%rcx, (%rdi)
+	addq	$8, %rdi
+.L2_13:
+	testb	$4, %dxl
+	je	.L2_15
+	movl	(%rsi), %ecx
+	addq	$4, %rsi
+	movl	%ecx, (%rdi)
+	addq	$4, %rdi
+.L2_15:
+	testb	$2, %dxl
+	je	.L2_17
+	movzwl	(%rsi), %ecx
+	addq	$2, %rsi
+	movw	%cx, (%rdi)
+	addq	$2, %rdi
+.L2_17:
+	testb	$1, %dxl
+	je	.L2_33
+.L2_1:
+	movzbl	(%rsi), %ecx
+	movb	%cl, (%rdi)
+.L2_33:
+	ret
+.L2_34:
+	cmpq	$63, %rdx	/* rdx is > 15 */
+	ja	.L2_64
+	movl	$16, %ecx	/* rdx is 16..63 */
+.L2_25:
+	movq	8(%rsi), %r8
+	movq	(%rsi), %r9
+	addq	%rcx, %rsi
+	movq	%r8, 8(%rdi)
+	movq	%r9, (%rdi)
+	addq	%rcx, %rdi
+	subq	%rcx, %rdx
+	cmpl	%edx, %ecx	/* is rdx >= 16? */
+	jbe	.L2_25
+	jmp	.L2_3		/* rdx is 0..15 */
+	.p2align 4,,7
+.L2_64:
+	movl	$64, %ecx
+.L2_42:
+	prefetchnta	256(%rsi)
+	movq	(%rsi), %r8
+	movq	8(%rsi), %r9
+	movq	16(%rsi), %r10
+	movq	24(%rsi), %r11
+	subq	%rcx, %rdx
+	movnti	%r8, (%rdi)
+	movq	32(%rsi), %r8
+	movnti	%r9, 8(%rdi)
+	movq	40(%rsi), %r9
+	movnti	%r10, 16(%rdi)
+	movq	48(%rsi), %r10
+	movnti	%r11, 24(%rdi)
+	movq	56(%rsi), %r11
+	addq	%rcx, %rsi
+	movnti	%r8, 32(%rdi)
+	movnti	%r9, 40(%rdi)
+	movnti	%r10, 48(%rdi)
+	movnti	%r11, 56(%rdi)
+	addq	%rcx, %rdi
+	cmpq	%rdx, %rcx	/* is rdx >= 64? */
+	jbe	.L2_42
+	sfence
+	orl	%edx, %edx
+	je	.L2_33
+	jmp	.L2_5
+.L2_9:
+	jmp	*.L2_12(,%rdx,8)	/* rdx is 0..8 */
+	.section	.rodata
+	.align 8
+	.align 4
+.L2_12:
+	.quad	.L2_33
+	.quad	.L2_1
+	.quad	.L2_2
+	.quad	.L2_6
+	.quad	.L2_4
+	.quad	.L2_6
+	.quad	.L2_6
+	.quad	.L2_6
+	.quad	.L2_8
+	.text
+.L2_2:
+	movzwl	(%rsi), %ecx
+	movw	%cx, (%rdi)
+	ret
+.L2_4:
+	movl	(%rsi), %ecx
+	movl	%ecx, (%rdi)
+	ret
+.L2_8:
+	movq	(%rsi), %rcx
+	movq	%rcx, (%rdi)
+	ret
