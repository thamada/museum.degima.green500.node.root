mlx4: add debug output in error path to assist in supporting the driver.

Add debug printouts in error path to provide a bit more detail.
The facility is on-off switchable at run-time
(i.e., module-parameter controlled, off by default).

Signed-off-by: Jack Morgenstein <jackm@dev.mellanox.co.il>

---

=============================================================
---
 drivers/infiniband/hw/mlx4/cq.c      |    4 -
 drivers/infiniband/hw/mlx4/main.c    |   10 ++-
 drivers/infiniband/hw/mlx4/mlx4_ib.h |   19 ++++++
 drivers/infiniband/hw/mlx4/qp.c      |  107 +++++++++++++++++++++++++++++------
 drivers/infiniband/hw/mlx4/srq.c     |   18 ++++-
 5 files changed, 135 insertions(+), 23 deletions(-)

Index: ofed_kernel/drivers/infiniband/hw/mlx4/cq.c
===================================================================
--- ofed_kernel.orig/drivers/infiniband/hw/mlx4/cq.c
+++ ofed_kernel/drivers/infiniband/hw/mlx4/cq.c
@@ -171,8 +171,10 @@ struct ib_cq *mlx4_ib_create_cq(struct i
 	struct mlx4_uar *uar;
 	int err;
 
-	if (entries < 1 || entries > dev->dev->caps.max_cqes)
+	if (entries < 1 || entries > dev->dev->caps.max_cqes) {
+		mlx4_ib_dbg("invalid num of entries: %d", entries);
 		return ERR_PTR(-EINVAL);
+	}
 
 	cq = kmalloc(sizeof *cq, GFP_KERNEL);
 	if (!cq)
Index: ofed_kernel/drivers/infiniband/hw/mlx4/main.c
===================================================================
--- ofed_kernel.orig/drivers/infiniband/hw/mlx4/main.c
+++ ofed_kernel/drivers/infiniband/hw/mlx4/main.c
@@ -45,7 +45,7 @@
 #include "user.h"
 #include "wc.h"
 
-#define DRV_NAME	"mlx4_ib"
+#define DRV_NAME	MLX4_IB_DRV_NAME
 #define DRV_VERSION	"1.0"
 #define DRV_RELDATE	"April 4, 2008"
 
@@ -54,6 +54,14 @@ MODULE_DESCRIPTION("Mellanox ConnectX HC
 MODULE_LICENSE("Dual BSD/GPL");
 MODULE_VERSION(DRV_VERSION);
 
+#ifdef CONFIG_MLX4_DEBUG
+
+int mlx4_ib_debug_level = 0;
+module_param_named(debug_level, mlx4_ib_debug_level, int, 0644);
+MODULE_PARM_DESC(debug_level, "Enable debug tracing if > 0");
+
+#endif /* CONFIG_MLX4_DEBUG */
+
 static const char mlx4_ib_version[] =
 	DRV_NAME ": Mellanox ConnectX InfiniBand driver v"
 	DRV_VERSION " (" DRV_RELDATE ")\n";
Index: ofed_kernel/drivers/infiniband/hw/mlx4/mlx4_ib.h
===================================================================
--- ofed_kernel.orig/drivers/infiniband/hw/mlx4/mlx4_ib.h
+++ ofed_kernel/drivers/infiniband/hw/mlx4/mlx4_ib.h
@@ -44,6 +44,25 @@
 #include <linux/mlx4/device.h>
 #include <linux/mlx4/doorbell.h>
 
+
+#define MLX4_IB_DRV_NAME	"mlx4_ib"
+
+#ifdef CONFIG_MLX4_DEBUG
+extern int mlx4_ib_debug_level;
+
+#define mlx4_ib_dbg(format, arg...) 		\
+	do {					\
+		if (mlx4_ib_debug_level) 	\
+			printk(KERN_DEBUG "<" MLX4_IB_DRV_NAME "> %s: " format "\n",\
+			__func__, ## arg);	\
+	} while (0)
+
+#else /* CONFIG_MLX4_DEBUG */
+
+#define mlx4_ib_dbg(format, arg...) do {} while (0)
+
+#endif /* CONFIG_MLX4_DEBUG */
+
 enum {
 	MLX4_IB_SQ_MIN_WQE_SHIFT = 6
 };
Index: ofed_kernel/drivers/infiniband/hw/mlx4/qp.c
===================================================================
--- ofed_kernel.orig/drivers/infiniband/hw/mlx4/qp.c
+++ ofed_kernel/drivers/infiniband/hw/mlx4/qp.c
@@ -291,19 +291,27 @@ static int set_rq_size(struct mlx4_ib_de
 	/* Sanity check RQ size before proceeding */
 	if (cap->max_recv_wr > dev->dev->caps.max_wqes - MLX4_IB_SQ_MAX_SPARE ||
 	    cap->max_recv_sge >
-		min(dev->dev->caps.max_sq_sg, dev->dev->caps.max_rq_sg))
+		min(dev->dev->caps.max_sq_sg, dev->dev->caps.max_rq_sg)) {
+		mlx4_ib_dbg("Requested RQ size (sge or wr) too large");
 		return -EINVAL;
+	}
 
 	if (has_srq) {
 		/* QPs attached to an SRQ should have no RQ */
-		if (cap->max_recv_wr)
+		if (cap->max_recv_wr) {
+			mlx4_ib_dbg("non-zero RQ size for QP using SRQ");
 			return -EINVAL;
+		}
 
 		qp->rq.wqe_cnt = qp->rq.max_gs = 0;
 	} else {
 		/* HW requires >= 1 RQ entry with >= 1 gather entry */
-		if (is_user && (!cap->max_recv_wr || !cap->max_recv_sge))
+		if (is_user && (!cap->max_recv_wr || !cap->max_recv_sge)) {
+			mlx4_ib_dbg("user QP RQ has 0 wr's or 0 sge's "
+				    "(wr: 0x%x, sge: 0x%x)", cap->max_recv_wr,
+				    cap->max_recv_sge);
 			return -EINVAL;
+		}
 
 		qp->rq.wqe_cnt	 = roundup_pow_of_two(max(1U, cap->max_recv_wr));
 		qp->rq.max_gs	 = roundup_pow_of_two(max(1U, cap->max_recv_sge));
@@ -337,16 +345,20 @@ static int set_kernel_sq_size(struct mlx
 	    cap->max_send_sge	 >
 		min(dev->dev->caps.max_sq_sg, dev->dev->caps.max_rq_sg) ||
 	    cap->max_inline_data + send_wqe_overhead(type, qp->flags) +
-	    sizeof (struct mlx4_wqe_inline_seg) > dev->dev->caps.max_sq_desc_sz)
+	    sizeof (struct mlx4_wqe_inline_seg) > dev->dev->caps.max_sq_desc_sz) {
+		mlx4_ib_dbg("Requested SQ resources exceed device maxima");
 		return -EINVAL;
+	}
 
 	/*
 	 * For MLX transport we need 2 extra S/G entries:
 	 * one for the header and one for the checksum at the end
 	 */
 	if ((type == IB_QPT_SMI || type == IB_QPT_GSI) &&
-	    cap->max_send_sge + 2 > dev->dev->caps.max_sq_sg)
+	    cap->max_send_sge + 2 > dev->dev->caps.max_sq_sg) {
+		mlx4_ib_dbg("No space for SQP hdr/csum sge's");
 		return -EINVAL;
+	}
 
 	s = max(cap->max_send_sge * sizeof (struct mlx4_wqe_data_seg),
 		cap->max_inline_data + sizeof (struct mlx4_wqe_inline_seg)) +
@@ -448,8 +460,10 @@ static int set_user_sq_size(struct mlx4_
 	if ((1 << ucmd->log_sq_bb_count) > dev->dev->caps.max_wqes	 ||
 	    ucmd->log_sq_stride >
 		ilog2(roundup_pow_of_two(dev->dev->caps.max_sq_desc_sz)) ||
-	    ucmd->log_sq_stride < MLX4_IB_MIN_SQ_STRIDE)
+	    ucmd->log_sq_stride < MLX4_IB_MIN_SQ_STRIDE) {
+		mlx4_ib_dbg("Requested max wqes or wqe stride exceeds max");
 		return -EINVAL;
+	}
 
 	qp->sq.wqe_cnt   = 1 << ucmd->log_sq_bb_count;
 	qp->sq.wqe_shift = ucmd->log_sq_stride;
@@ -496,23 +510,30 @@ static int create_qp_common(struct mlx4_
 				       qp->buf_size, 0, 0);
 		if (IS_ERR(qp->umem)) {
 			err = PTR_ERR(qp->umem);
+			mlx4_ib_dbg("ib_umem_get error (%d)", err);
 			goto err;
 		}
 
 		err = mlx4_mtt_init(dev->dev, ib_umem_page_count(qp->umem),
 				    ilog2(qp->umem->page_size), &qp->mtt);
-		if (err)
+		if (err) {
+			mlx4_ib_dbg("mlx4_mtt_init error (%d)", err);
 			goto err_buf;
+		}
 
 		err = mlx4_ib_umem_write_mtt(dev, &qp->mtt, qp->umem);
-		if (err)
+		if (err) {
+			mlx4_ib_dbg("mlx4_ib_umem_write_mtt error (%d)", err);
 			goto err_mtt;
+		}
 
 		if (!init_attr->srq) {
 			err = mlx4_ib_db_map_user(to_mucontext(pd->uobject->context),
 						  ucmd.db_addr, &qp->db);
-			if (err)
+			if (err) {
+				mlx4_ib_dbg("mlx4_ib_db_map_user error (%d)", err);
 				goto err_mtt;
+			}
 		}
 	} else {
 		qp->sq_no_prefetch = 0;
@@ -542,12 +563,16 @@ static int create_qp_common(struct mlx4_
 
 		err = mlx4_mtt_init(dev->dev, qp->buf.npages, qp->buf.page_shift,
 				    &qp->mtt);
-		if (err)
+		if (err) {
+			mlx4_ib_dbg("kernel qp mlx4_mtt_init error (%d)", err);
 			goto err_buf;
+		}
 
 		err = mlx4_buf_write_mtt(dev->dev, &qp->mtt, &qp->buf);
-		if (err)
+		if (err) {
+			mlx4_ib_dbg("mlx4_buf_write_mtt error (%d)", err);
 			goto err_mtt;
+		}
 
 		qp->sq.wrid  = kmalloc(qp->sq.wqe_cnt * sizeof (u64), GFP_KERNEL);
 		qp->rq.wrid  = kmalloc(qp->rq.wqe_cnt * sizeof (u64), GFP_KERNEL);
@@ -728,8 +753,10 @@ struct ib_qp *mlx4_ib_create_qp(struct i
 	case IB_QPT_GSI:
 	{
 		/* Userspace is not allowed to create special QPs: */
-		if (pd->uobject)
+		if (pd->uobject) {
+			mlx4_ib_dbg("Userspace is not allowed to create special QPs");
 			return ERR_PTR(-EINVAL);
+		}
 
 		sqp = kzalloc(sizeof *sqp, GFP_KERNEL);
 		if (!sqp)
@@ -754,6 +781,8 @@ struct ib_qp *mlx4_ib_create_qp(struct i
 	}
 	default:
 		/* Don't support raw QPs */
+		mlx4_ib_dbg("Invalid QP type requested for create_qp (%d)",
+			    init_attr->qp_type);
 		return ERR_PTR(-EINVAL);
 	}
 
@@ -960,8 +989,11 @@ static int __mlx4_ib_modify_qp(struct ib
 
 	if (attr_mask & IB_QP_AV) {
 		if (mlx4_set_path(dev, &attr->ah_attr, &context->pri_path,
-				  attr_mask & IB_QP_PORT ? attr->port_num : qp->port))
+				  attr_mask & IB_QP_PORT ? attr->port_num : qp->port)) {
+			mlx4_ib_dbg("qpn 0x%x: could not set pri path params",
+				    ibqp->qp_num);
 			goto out;
+		}
 
 		optpar |= (MLX4_QP_OPTPAR_PRIMARY_ADDR_PATH |
 			   MLX4_QP_OPTPAR_SCHED_QUEUE);
@@ -974,16 +1006,25 @@ static int __mlx4_ib_modify_qp(struct ib
 
 	if (attr_mask & IB_QP_ALT_PATH) {
 		if (attr->alt_port_num == 0 ||
-		    attr->alt_port_num > dev->dev->caps.num_ports)
+		    attr->alt_port_num > dev->dev->caps.num_ports) {
+			mlx4_ib_dbg("qpn 0x%x: invalid alternate port num (%d)",
+				    ibqp->qp_num, attr->alt_port_num);
 			goto out;
+		}
 
 		if (attr->alt_pkey_index >=
-		    dev->dev->caps.pkey_table_len[attr->alt_port_num])
+		    dev->dev->caps.pkey_table_len[attr->alt_port_num]) {
+			mlx4_ib_dbg("qpn 0x%x: invalid alt pkey index (0x%x)",
+				    ibqp->qp_num, attr->alt_pkey_index);
 			goto out;
+		}
 
 		if (mlx4_set_path(dev, &attr->alt_ah_attr, &context->alt_path,
-				  attr->alt_port_num))
+				  attr->alt_port_num)) {
+			mlx4_ib_dbg("qpn 0x%x: could not set alt path params",
+				    ibqp->qp_num);
 			goto out;
+		}
 
 		context->alt_path.pkey_index = attr->alt_pkey_index;
 		context->alt_path.ackto = attr->alt_timeout << 3;
@@ -1163,27 +1204,49 @@ int mlx4_ib_modify_qp(struct ib_qp *ibqp
 	cur_state = attr_mask & IB_QP_CUR_STATE ? attr->cur_qp_state : qp->state;
 	new_state = attr_mask & IB_QP_STATE ? attr->qp_state : cur_state;
 
-	if (!ib_modify_qp_is_ok(cur_state, new_state, ibqp->qp_type, attr_mask))
+	if (!ib_modify_qp_is_ok(cur_state, new_state, ibqp->qp_type, attr_mask)) {
+		mlx4_ib_dbg("qpn 0x%x: invalid attribute mask specified "
+			    "for transition %d to %d. qp_type %d, attr_mask 0x%x",
+			    ibqp->qp_num, cur_state, new_state,
+			    ibqp->qp_type, attr_mask);
 		goto out;
+	}
 
 	if ((attr_mask & IB_QP_PORT) &&
 	    (attr->port_num == 0 || attr->port_num > dev->dev->caps.num_ports)) {
+		mlx4_ib_dbg("qpn 0x%x: invalid port number (%d) specified "
+			    "for transition %d to %d. qp_type %d",
+			    ibqp->qp_num, attr->port_num, cur_state,
+			    new_state, ibqp->qp_type);
 		goto out;
 	}
 
 	if (attr_mask & IB_QP_PKEY_INDEX) {
 		int p = attr_mask & IB_QP_PORT ? attr->port_num : qp->port;
-		if (attr->pkey_index >= dev->dev->caps.pkey_table_len[p])
+		if (attr->pkey_index >= dev->dev->caps.pkey_table_len[p]) {
+			mlx4_ib_dbg("qpn 0x%x: invalid pkey index (%d) specified "
+				    "for transition %d to %d. qp_type %d",
+				    ibqp->qp_num, attr->pkey_index, cur_state,
+				    new_state, ibqp->qp_type);
 			goto out;
+		}
 	}
 
 	if (attr_mask & IB_QP_MAX_QP_RD_ATOMIC &&
 	    attr->max_rd_atomic > dev->dev->caps.max_qp_init_rdma) {
+		mlx4_ib_dbg("qpn 0x%x: max_rd_atomic (%d) too large. "
+			    "Transition %d to %d. qp_type %d",
+			    ibqp->qp_num, attr->max_rd_atomic, cur_state,
+			    new_state, ibqp->qp_type);
 		goto out;
 	}
 
 	if (attr_mask & IB_QP_MAX_DEST_RD_ATOMIC &&
 	    attr->max_dest_rd_atomic > dev->dev->caps.max_qp_dest_rdma) {
+		mlx4_ib_dbg("qpn 0x%x: max_dest_rd_atomic (%d) too large. "
+			    "Transition %d to %d. qp_type %d",
+			    ibqp->qp_num, attr->max_dest_rd_atomic, cur_state,
+			    new_state, ibqp->qp_type);
 		goto out;
 	}
 
@@ -1252,6 +1315,8 @@ static int build_mlx_header(struct mlx4_
 		sqp->ud_header.immediate_data    = wr->ex.imm_data;
 		break;
 	default:
+		mlx4_ib_dbg("special QP type %d: invalid wr opcode 0x%x",
+			    sqp->qp.ibqp.qp_type, wr->opcode);
 		return -EINVAL;
 	}
 
@@ -1513,12 +1578,15 @@ int mlx4_ib_post_send(struct ib_qp *ibqp
 
 	for (nreq = 0; wr; ++nreq, wr = wr->next) {
 		if (mlx4_wq_overflow(&qp->sq, nreq, qp->ibqp.send_cq)) {
+			mlx4_ib_dbg("QP 0x%x: WQE overflow", ibqp->qp_num);
 			err = -ENOMEM;
 			*bad_wr = wr;
 			goto out;
 		}
 
 		if (unlikely(wr->num_sge > qp->sq.max_gs)) {
+			mlx4_ib_dbg("QP 0x%x: too many sg entries (%d)",
+				    ibqp->qp_num, wr->num_sge);
 			err = -EINVAL;
 			*bad_wr = wr;
 			goto out;
@@ -1723,12 +1791,15 @@ int mlx4_ib_post_recv(struct ib_qp *ibqp
 
 	for (nreq = 0; wr; ++nreq, wr = wr->next) {
 		if (mlx4_wq_overflow(&qp->rq, nreq, qp->ibqp.send_cq)) {
+			mlx4_ib_dbg("QP 0x%x: WQE overflow", ibqp->qp_num);
 			err = -ENOMEM;
 			*bad_wr = wr;
 			goto out;
 		}
 
 		if (unlikely(wr->num_sge > qp->rq.max_gs)) {
+			mlx4_ib_dbg("QP 0x%x: too many sg entries (%d)",
+				    ibqp->qp_num, wr->num_sge);
 			err = -EINVAL;
 			*bad_wr = wr;
 			goto out;
Index: ofed_kernel/drivers/infiniband/hw/mlx4/srq.c
===================================================================
--- ofed_kernel.orig/drivers/infiniband/hw/mlx4/srq.c
+++ ofed_kernel/drivers/infiniband/hw/mlx4/srq.c
@@ -81,8 +81,12 @@ struct ib_srq *mlx4_ib_create_srq(struct
 
 	/* Sanity check SRQ size before proceeding */
 	if (init_attr->attr.max_wr  >= dev->dev->caps.max_srq_wqes ||
-	    init_attr->attr.max_sge >  dev->dev->caps.max_srq_sge)
+	    init_attr->attr.max_sge >  dev->dev->caps.max_srq_sge) {
+		mlx4_ib_dbg("a size param is out of range. "
+			    "max_wr = 0x%x, max_sge = 0x%x",
+			    init_attr->attr.max_wr, init_attr->attr.max_sge);
 		return ERR_PTR(-EINVAL);
+	}
 
 	srq = kmalloc(sizeof *srq, GFP_KERNEL);
 	if (!srq)
@@ -217,12 +221,16 @@ int mlx4_ib_modify_srq(struct ib_srq *ib
 	int ret;
 
 	/* We don't support resizing SRQs (yet?) */
-	if (attr_mask & IB_SRQ_MAX_WR)
+	if (attr_mask & IB_SRQ_MAX_WR) {
+		mlx4_ib_dbg("resize not yet supported");
 		return -EINVAL;
+	}
 
 	if (attr_mask & IB_SRQ_LIMIT) {
-		if (attr->srq_limit >= srq->msrq.max)
+		if (attr->srq_limit >= srq->msrq.max){
+			mlx4_ib_dbg("limit (0x%x) too high", attr->srq_limit);
 			return -EINVAL;
+		}
 
 		mutex_lock(&srq->mutex);
 		ret = mlx4_srq_arm(dev->dev, &srq->msrq, attr->srq_limit);
@@ -305,12 +313,16 @@ int mlx4_ib_post_srq_recv(struct ib_srq 
 
 	for (nreq = 0; wr; ++nreq, wr = wr->next) {
 		if (unlikely(wr->num_sge > srq->msrq.max_gs)) {
+			mlx4_ib_dbg("srq num 0x%x: num s/g entries too large (%d)",
+				    srq->msrq.srqn, wr->num_sge);
 			err = -EINVAL;
 			*bad_wr = wr;
 			break;
 		}
 
 		if (unlikely(srq->head == srq->tail)) {
+			mlx4_ib_dbg("srq num 0x%x: No entries available to post.",
+				    srq->msrq.srqn);
 			err = -ENOMEM;
 			*bad_wr = wr;
 			break;
