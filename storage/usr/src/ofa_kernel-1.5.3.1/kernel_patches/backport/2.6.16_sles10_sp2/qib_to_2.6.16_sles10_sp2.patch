diff -up a/drivers/infiniband/hw/qib/Makefile b/drivers/infiniband/hw/qib/Makefile
--- a/drivers/infiniband/hw/qib/Makefile        2010-04-20 16:01:02.000000000 -0700
+++ b/drivers/infiniband/hw/qib/Makefile        2010-04-20 15:58:04.000000000 -0700
@@ -1,4 +1,4 @@
-ccflags-y += -DQIB_KERN_TYPE=0 -DQIB_IDSTR='"QLogic kernel.org driver"'
+EXTRA_CFLAGS += -DQIB_KERN_TYPE=0 -DQIB_IDSTR='"QLogic kernel.org driver"'

 obj-$(CONFIG_INFINIBAND_QIB) += ib_qib.o

diff --git a/drivers/infiniband/hw/qib/qib.h b/drivers/infiniband/hw/qib/qib.h
index 305f9b6..5c68f12 100644
--- a/drivers/infiniband/hw/qib/qib.h
+++ b/drivers/infiniband/hw/qib/qib.h
@@ -660,8 +660,8 @@ struct qib_devdata {
 	struct pci_dev *pcidev;
 	struct cdev *user_cdev;
 	struct cdev *diag_cdev;
-	struct device *user_device;
-	struct device *diag_device;
+	struct class_device *user_class_dev;
+	struct class_device *diag_class_dev;
 
 	/* mem-mapped pointer to base of chip regs */
 	u64 __iomem *kregbase;
@@ -1055,8 +1055,8 @@ int qib_count_active_units(void);
 
 int qib_cdev_init(int minor, const char *name,
 		  const struct file_operations *fops,
-		  struct cdev **cdevp, struct device **devp);
-void qib_cdev_cleanup(struct cdev **cdevp, struct device **devp);
+		  struct cdev **cdevp, struct class_device **class_devp);
+void qib_cdev_cleanup(struct cdev **cdevp, struct class_device **class_devp);
 int qib_dev_init(void);
 void qib_dev_cleanup(void);
 
@@ -1468,4 +1468,10 @@ struct qib_hwerror_msgs {
 void qib_format_hwerrors(u64 hwerrs,
 			 const struct qib_hwerror_msgs *hwerrmsgs,
 			 size_t nhwerrmsgs, char *msg, size_t lmsg);
+
+#define time_after64(a,b)       \
+	(typecheck(__u64, a) && \
+	typecheck(__u64, b) && \
+	((__s64)(b) - (__s64)(a) < 0))
+
 #endif                          /* _QIB_KERNEL_H */
diff --git a/drivers/infiniband/hw/qib/qib_cq.c b/drivers/infiniband/hw/qib/qib_cq.c
index e0f4ac8..245d391 100644
--- a/drivers/infiniband/hw/qib/qib_cq.c
+++ b/drivers/infiniband/hw/qib/qib_cq.c
@@ -322,7 +322,7 @@ int qib_destroy_cq(struct ib_cq *ibcq)
 	struct qib_ibdev *dev = to_idev(ibcq->device);
 	struct qib_cq *cq = to_icq(ibcq);
 
-	flush_work(&cq->comptask);
+	flush_workqueue(qib_cq_wq);
 	spin_lock(&dev->n_cqs_lock);
 	dev->n_cqs_allocated--;
 	spin_unlock(&dev->n_cqs_lock);
diff --git a/drivers/infiniband/hw/qib/qib_diag.c b/drivers/infiniband/hw/qib/qib_diag.c
index 74ab8e8..877b291 100644
--- a/drivers/infiniband/hw/qib/qib_diag.c
+++ b/drivers/infiniband/hw/qib/qib_diag.c
@@ -46,7 +46,7 @@
 #include <linux/poll.h>
 #include <linux/vmalloc.h>
 #include <linux/fs.h>
-#include <linux/uaccess.h>
+#include <asm/uaccess.h>
 
 #include "qib.h"
 #include "qib_common.h"
@@ -140,7 +140,7 @@ static const struct file_operations diag_file_ops = {
 
 static atomic_t diagpkt_count = ATOMIC_INIT(0);
 static struct cdev *diagpkt_cdev;
-static struct device *diagpkt_device;
+static struct class_device *diagpkt_class_dev;
 
 static ssize_t qib_diagpkt_write(struct file *fp, const char __user *data,
 				 size_t count, loff_t *off);
@@ -158,7 +158,7 @@ int qib_diag_add(struct qib_devdata *dd)
 	if (atomic_inc_return(&diagpkt_count) == 1) {
 		ret = qib_cdev_init(QIB_DIAGPKT_MINOR, "ipath_diagpkt",
 				    &diagpkt_file_ops, &diagpkt_cdev,
-				    &diagpkt_device);
+				    &diagpkt_class_dev);
 		if (ret)
 			goto done;
 	}
@@ -166,7 +166,7 @@ int qib_diag_add(struct qib_devdata *dd)
 	snprintf(name, sizeof(name), "ipath_diag%d", dd->unit);
 	ret = qib_cdev_init(QIB_DIAG_MINOR_BASE + dd->unit, name,
 			    &diag_file_ops, &dd->diag_cdev,
-			    &dd->diag_device);
+			    &dd->diag_class_dev);
 done:
 	return ret;
 }
@@ -178,9 +178,9 @@ void qib_diag_remove(struct qib_devdata *dd)
 	struct qib_diag_client *dc;
 
 	if (atomic_dec_and_test(&diagpkt_count))
-		qib_cdev_cleanup(&diagpkt_cdev, &diagpkt_device);
+		qib_cdev_cleanup(&diagpkt_cdev, &diagpkt_class_dev);
 
-	qib_cdev_cleanup(&dd->diag_cdev, &dd->diag_device);
+	qib_cdev_cleanup(&dd->diag_cdev, &dd->diag_class_dev);
 
 	/*
 	 * Return all diag_clients of this device. There should be none,
diff --git a/drivers/infiniband/hw/qib/qib_file_ops.c b/drivers/infiniband/hw/qib/qib_file_ops.c
index ceaf4f2..fce442c 100644
--- a/drivers/infiniband/hw/qib/qib_file_ops.c
+++ b/drivers/infiniband/hw/qib/qib_file_ops.c
@@ -52,15 +52,15 @@
 static int qib_open(struct inode *, struct file *);
 static int qib_close(struct inode *, struct file *);
 static ssize_t qib_write(struct file *, const char __user *, size_t, loff_t *);
-static ssize_t qib_aio_write(struct kiocb *, const struct iovec *,
-			     unsigned long, loff_t);
+static ssize_t qib_writev(struct file *, const struct iovec *,
+			  unsigned long , loff_t *);
 static unsigned int qib_poll(struct file *, struct poll_table_struct *);
 static int qib_mmapf(struct file *, struct vm_area_struct *);
 
 static const struct file_operations qib_file_ops = {
 	.owner = THIS_MODULE,
 	.write = qib_write,
-	.aio_write = qib_aio_write,
+	.writev = qib_writev,
 	.open = qib_open,
 	.release = qib_close,
 	.poll = qib_poll,
@@ -968,24 +968,33 @@ bail:
 }
 
 /*
- * qib_file_vma_fault - handle a VMA page fault.
+ * qib_file_vma_nopage - handle a VMA page fault.
  */
-static int qib_file_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+static struct page *qib_file_vma_nopage(struct vm_area_struct *vma,
+					unsigned long address, int *type)
 {
-	struct page *page;
+	unsigned long offset = address - vma->vm_start;
+	struct page *page = NOPAGE_SIGBUS;
+	void *pageptr;
 
-	page = vmalloc_to_page((void *)(vmf->pgoff << PAGE_SHIFT));
+	/*
+	 * Convert the vmalloc address into a struct page.
+	 */
+	pageptr = (void *)(offset + (vma->vm_pgoff << PAGE_SHIFT));
+	page = vmalloc_to_page(pageptr);
 	if (!page)
-		return VM_FAULT_SIGBUS;
+		goto out;
 
+	/* Increment the reference count. */
 	get_page(page);
-	vmf->page = page;
-
-	return 0;
+	if (type)
+		*type = VM_FAULT_MINOR;
+out:
+	return page;
 }
 
 static struct vm_operations_struct qib_file_vm_ops = {
-	.fault = qib_file_vma_fault,
+	.nopage = qib_file_vma_nopage,
 };
 
 static int mmap_kvaddr(struct vm_area_struct *vma, u64 pgaddr,
@@ -2351,11 +2360,11 @@ bail:
 	return ret;
 }
 
-static ssize_t qib_aio_write(struct kiocb *iocb, const struct iovec *iov,
-			     unsigned long dim, loff_t off)
+static ssize_t qib_writev(struct file *filp, const struct iovec *iov,
+			  unsigned long dim, loff_t *off)
 {
-	struct qib_filedata *fp = iocb->ki_filp->private_data;
-	struct qib_ctxtdata *rcd = ctxt_fp(iocb->ki_filp);
+	struct qib_filedata *fp = filp->private_data;
+	struct qib_ctxtdata *rcd = ctxt_fp(filp);
 	struct qib_user_sdma_queue *pq = fp->pq;
 
 	if (!dim || !pq)
@@ -2369,11 +2378,11 @@ static dev_t qib_dev;
 
 int qib_cdev_init(int minor, const char *name,
 		  const struct file_operations *fops,
-		  struct cdev **cdevp, struct device **devp)
+		  struct cdev **cdevp, struct class_device **class_devp)
 {
 	const dev_t dev = MKDEV(MAJOR(qib_dev), minor);
 	struct cdev *cdev;
-	struct device *device = NULL;
+	struct class_device *class_dev = NULL;
 	int ret;
 
 	cdev = cdev_alloc();
@@ -2386,7 +2395,7 @@ int qib_cdev_init(int minor, const char *name,
 	}
 
 	cdev->owner = THIS_MODULE;
-	cdev->ops = fops;
+	cdev->ops = (struct file_operations *) fops;
 	kobject_set_name(&cdev->kobj, name);
 
 	ret = cdev_add(cdev, dev, 1);
@@ -2397,11 +2406,12 @@ int qib_cdev_init(int minor, const char *name,
 		goto err_cdev;
 	}
 
-	device = device_create(qib_class, NULL, dev, NULL, name);
-	if (!IS_ERR(device))
+	class_dev = class_device_create(qib_class, NULL, dev, NULL,
+					(char *)name);
+	if (!IS_ERR(class_dev))
 		goto done;
-	ret = PTR_ERR(device);
-	device = NULL;
+	ret = PTR_ERR(class_dev);
+	class_dev = NULL;
 	printk(KERN_ERR QIB_DRV_NAME ": Could not create "
 	       "device for minor %d, %s (err %d)\n",
 	       minor, name, -ret);
@@ -2410,17 +2420,17 @@ err_cdev:
 	cdev = NULL;
 done:
 	*cdevp = cdev;
-	*devp = device;
+	*class_devp = class_dev;
 	return ret;
 }
 
-void qib_cdev_cleanup(struct cdev **cdevp, struct device **devp)
+void qib_cdev_cleanup(struct cdev **cdevp, struct class_device **class_devp)
 {
-	struct device *device = *devp;
+	struct class_device *class_dev = *class_devp;
 
-	if (device) {
-		device_unregister(device);
-		*devp = NULL;
+	if (class_dev) {
+		class_device_unregister(class_dev);
+		*class_devp = NULL;
 	}
 
 	if (*cdevp) {
@@ -2430,7 +2440,7 @@ void qib_cdev_cleanup(struct cdev **cdevp, struct device **devp)
 }
 
 static struct cdev *wildcard_cdev;
-static struct device *wildcard_device;
+static struct class_device *wildcard_class_dev;
 
 int __init qib_dev_init(void)
 {
@@ -2470,9 +2480,9 @@ static atomic_t user_count = ATOMIC_INIT(0);
 static void qib_user_remove(struct qib_devdata *dd)
 {
 	if (atomic_dec_return(&user_count) == 0)
-		qib_cdev_cleanup(&wildcard_cdev, &wildcard_device);
+		qib_cdev_cleanup(&wildcard_cdev, &wildcard_class_dev);
 
-	qib_cdev_cleanup(&dd->user_cdev, &dd->user_device);
+	qib_cdev_cleanup(&dd->user_cdev, &dd->user_class_dev);
 }
 
 static int qib_user_add(struct qib_devdata *dd)
@@ -2482,14 +2492,14 @@ static int qib_user_add(struct qib_devdata *dd)
 
 	if (atomic_inc_return(&user_count) == 1) {
 		ret = qib_cdev_init(0, "ipath", &qib_file_ops,
-				    &wildcard_cdev, &wildcard_device);
+				    &wildcard_cdev, &wildcard_class_dev);
 		if (ret)
 			goto done;
 	}
 
 	snprintf(name, sizeof(name), "ipath%d", dd->unit);
 	ret = qib_cdev_init(dd->unit + 1, name, &qib_file_ops,
-			    &dd->user_cdev, &dd->user_device);
+			    &dd->user_cdev, &dd->user_class_dev);
 	if (ret)
 		qib_user_remove(dd);
 done:
diff --git a/drivers/infiniband/hw/qib/qib_fs.c b/drivers/infiniband/hw/qib/qib_fs.c
index 629ff7e..3a328e6 100644
--- a/drivers/infiniband/hw/qib/qib_fs.c
+++ b/drivers/infiniband/hw/qib/qib_fs.c
@@ -72,7 +72,7 @@ static int qibfs_mknod(struct inode *dir, struct dentry *dentry,
 		inc_nlink(dir);
 	}
 
-	inode->i_fop = fops;
+	inode->i_fop = (struct file_operations *) fops;
 
 	d_instantiate(dentry, inode);
 	error = 0;
@@ -457,8 +457,10 @@ static int qibfs_fill_super(struct super_block *sb, void *data, int silent)
 	int ret;
 
 	static struct tree_descr files[] = {
-		[2] = {"driver_stats", &driver_ops[0], S_IRUGO},
-		[3] = {"driver_stats_names", &driver_ops[1], S_IRUGO},
+		[2] = {"driver_stats",
+			(struct file_operations *)&driver_ops[0], S_IRUGO},
+		[3] = {"driver_stats_names",
+			(struct file_operations *)&driver_ops[1], S_IRUGO},
 		{""},
 	};
 
@@ -486,14 +488,12 @@ bail:
 	return ret;
 }
 
-static int qibfs_get_sb(struct file_system_type *fs_type, int flags,
-			const char *dev_name, void *data, struct vfsmount *mnt)
+static struct super_block *qibfs_get_sb(struct file_system_type *fs_type,
+					int flags, const char *dev_name,
+					void *data)
 {
-	int ret = get_sb_single(fs_type, flags, data,
-				qibfs_fill_super, mnt);
-	if (ret >= 0)
-		qib_super = mnt->mnt_sb;
-	return ret;
+	qib_super = get_sb_single(fs_type, flags, data, qibfs_fill_super);
+	return qib_super;
 }
 
 static void qibfs_kill_super(struct super_block *s)
diff --git a/drivers/infiniband/hw/qib/qib_iba7322.c b/drivers/infiniband/hw/qib/qib_iba7322.c
index 4e3a621..b83f797 100644
--- a/drivers/infiniband/hw/qib/qib_iba7322.c
+++ b/drivers/infiniband/hw/qib/qib_iba7322.c
@@ -1395,16 +1395,16 @@ static void flush_fifo(struct qib_pportdata *ppd)
 	u64 pbc;
 	const unsigned hdrwords = 7;
 	static struct qib_ib_header ibhdr = {
-		.lrh[0] = cpu_to_be16(0xF000 | QIB_LRH_BTH),
+		.lrh[0] = __constant_cpu_to_be16(0xF000 | QIB_LRH_BTH),
 		.lrh[1] = IB_LID_PERMISSIVE,
-		.lrh[2] = cpu_to_be16(hdrwords + SIZE_OF_CRC),
+		.lrh[2] = __constant_cpu_to_be16(hdrwords + SIZE_OF_CRC),
 		.lrh[3] = IB_LID_PERMISSIVE,
-		.u.oth.bth[0] = cpu_to_be32(
+		.u.oth.bth[0] = __constant_cpu_to_be32(
 			(IB_OPCODE_UD_SEND_ONLY << 24) | QIB_DEFAULT_P_KEY),
-		.u.oth.bth[1] = cpu_to_be32(0),
-		.u.oth.bth[2] = cpu_to_be32(0),
-		.u.oth.u.ud.deth[0] = cpu_to_be32(0),
-		.u.oth.u.ud.deth[1] = cpu_to_be32(0),
+		.u.oth.bth[1] = __constant_cpu_to_be32(0),
+		.u.oth.bth[2] = __constant_cpu_to_be32(0),
+		.u.oth.u.ud.deth[0] = __constant_cpu_to_be32(0),
+		.u.oth.u.ud.deth[1] = __constant_cpu_to_be32(0),
 	};
 
 	/*
@@ -5490,7 +5490,7 @@ static void try_7322_ipg(struct qib_pportdata *ppd)
 		struct ib_ah *ah;
 
 		memset(&attr, 0, sizeof attr);
-		attr.dlid = be16_to_cpu(IB_LID_PERMISSIVE);
+		attr.dlid = __constant_be16_to_cpu(IB_LID_PERMISSIVE);
 		attr.port_num = ppd->port;
 		ah = ib_create_ah(ibp->qp0->ibqp.pd, &attr);
 		if (IS_ERR(ah))
diff --git a/drivers/infiniband/hw/qib/qib_mad.c b/drivers/infiniband/hw/qib/qib_mad.c
index f6a71ae..2c6b3ff 100644
--- a/drivers/infiniband/hw/qib/qib_mad.c
+++ b/drivers/infiniband/hw/qib/qib_mad.c
@@ -88,7 +88,7 @@ static void qib_send_trap(struct qib_ibport *ibp, void *data, unsigned len)
 
 	spin_lock_irqsave(&ibp->lock, flags);
 	if (!ibp->sm_ah) {
-		if (ibp->sm_lid != be16_to_cpu(IB_LID_PERMISSIVE)) {
+		if (ibp->sm_lid != __constant_be16_to_cpu(IB_LID_PERMISSIVE)) {
 			struct ib_ah *ah;
 			struct ib_ah_attr attr;
 
@@ -1400,7 +1400,7 @@ static int pma_get_portsamplesresult_ext(struct ib_perf *pmp,
 		status = dd->f_portcntr(ppd, QIBPORTCNTR_PSSTAT);
 		p->sample_status = cpu_to_be16(status);
 		/* 64 bits */
-		p->extended_width = cpu_to_be32(0x80000000);
+		p->extended_width = __constant_cpu_to_be32(0x80000000);
 		if (status == IB_PMA_SAMPLE_STATUS_DONE) {
 			cache_hw_sample_counters(ppd);
 			ppd->cong_stats.counter =
@@ -1457,7 +1457,7 @@ static int pma_get_portcounters(struct ib_perf *pmp,
 		pmp->status |= IB_SMP_INVALID_FIELD;
 
 	if (cntrs.symbol_error_counter > 0xFFFFUL)
-		p->symbol_error_counter = cpu_to_be16(0xFFFF);
+		p->symbol_error_counter = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->symbol_error_counter =
 			cpu_to_be16((u16)cntrs.symbol_error_counter);
@@ -1471,17 +1471,17 @@ static int pma_get_portcounters(struct ib_perf *pmp,
 	else
 		p->link_downed_counter = (u8)cntrs.link_downed_counter;
 	if (cntrs.port_rcv_errors > 0xFFFFUL)
-		p->port_rcv_errors = cpu_to_be16(0xFFFF);
+		p->port_rcv_errors = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_rcv_errors =
 			cpu_to_be16((u16) cntrs.port_rcv_errors);
 	if (cntrs.port_rcv_remphys_errors > 0xFFFFUL)
-		p->port_rcv_remphys_errors = cpu_to_be16(0xFFFF);
+		p->port_rcv_remphys_errors = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_rcv_remphys_errors =
 			cpu_to_be16((u16)cntrs.port_rcv_remphys_errors);
 	if (cntrs.port_xmit_discards > 0xFFFFUL)
-		p->port_xmit_discards = cpu_to_be16(0xFFFF);
+		p->port_xmit_discards = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_xmit_discards =
 			cpu_to_be16((u16)cntrs.port_xmit_discards);
@@ -1492,24 +1492,24 @@ static int pma_get_portcounters(struct ib_perf *pmp,
 	p->lli_ebor_errors = (cntrs.local_link_integrity_errors << 4) |
 		cntrs.excessive_buffer_overrun_errors;
 	if (cntrs.vl15_dropped > 0xFFFFUL)
-		p->vl15_dropped = cpu_to_be16(0xFFFF);
+		p->vl15_dropped = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->vl15_dropped = cpu_to_be16((u16)cntrs.vl15_dropped);
 	if (cntrs.port_xmit_data > 0xFFFFFFFFUL)
-		p->port_xmit_data = cpu_to_be32(0xFFFFFFFF);
+		p->port_xmit_data = __constant_cpu_to_be32(0xFFFFFFFF);
 	else
 		p->port_xmit_data = cpu_to_be32((u32)cntrs.port_xmit_data);
 	if (cntrs.port_rcv_data > 0xFFFFFFFFUL)
-		p->port_rcv_data = cpu_to_be32(0xFFFFFFFF);
+		p->port_rcv_data = __constant_cpu_to_be32(0xFFFFFFFF);
 	else
 		p->port_rcv_data = cpu_to_be32((u32)cntrs.port_rcv_data);
 	if (cntrs.port_xmit_packets > 0xFFFFFFFFUL)
-		p->port_xmit_packets = cpu_to_be32(0xFFFFFFFF);
+		p->port_xmit_packets = __constant_cpu_to_be32(0xFFFFFFFF);
 	else
 		p->port_xmit_packets =
 			cpu_to_be32((u32)cntrs.port_xmit_packets);
 	if (cntrs.port_rcv_packets > 0xFFFFFFFFUL)
-		p->port_rcv_packets = cpu_to_be32(0xFFFFFFFF);
+		p->port_rcv_packets = __constant_cpu_to_be32(0xFFFFFFFF);
 	else
 		p->port_rcv_packets =
 			cpu_to_be32((u32) cntrs.port_rcv_packets);
@@ -1576,7 +1576,7 @@ static int pma_get_portcounters_cong(struct ib_perf *pmp,
 		cpu_to_be16((QIB_XMIT_RATE_PICO << 13) |
 			    (dd->psxmitwait_check_rate &
 			     ~(QIB_XMIT_RATE_PICO << 13)));
-	p->port_adr_events = cpu_to_be64(0);
+	p->port_adr_events = __constant_cpu_to_be64(0);
 	p->port_xmit_wait = cpu_to_be64(xmit_wait_counter);
 	p->port_xmit_data = cpu_to_be64(cntrs.port_xmit_data);
 	p->port_rcv_data = cpu_to_be64(cntrs.port_rcv_data);
@@ -1585,7 +1585,7 @@ static int pma_get_portcounters_cong(struct ib_perf *pmp,
 	p->port_rcv_packets =
 		cpu_to_be64(cntrs.port_rcv_packets);
 	if (cntrs.symbol_error_counter > 0xFFFFUL)
-		p->symbol_error_counter = cpu_to_be16(0xFFFF);
+		p->symbol_error_counter = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->symbol_error_counter =
 			cpu_to_be16(
@@ -1601,18 +1601,18 @@ static int pma_get_portcounters_cong(struct ib_perf *pmp,
 		p->link_downed_counter =
 			(u8)cntrs.link_downed_counter;
 	if (cntrs.port_rcv_errors > 0xFFFFUL)
-		p->port_rcv_errors = cpu_to_be16(0xFFFF);
+		p->port_rcv_errors = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_rcv_errors =
 			cpu_to_be16((u16) cntrs.port_rcv_errors);
 	if (cntrs.port_rcv_remphys_errors > 0xFFFFUL)
-		p->port_rcv_remphys_errors = cpu_to_be16(0xFFFF);
+		p->port_rcv_remphys_errors = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_rcv_remphys_errors =
 			cpu_to_be16(
 				(u16)cntrs.port_rcv_remphys_errors);
 	if (cntrs.port_xmit_discards > 0xFFFFUL)
-		p->port_xmit_discards = cpu_to_be16(0xFFFF);
+		p->port_xmit_discards = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->port_xmit_discards =
 			cpu_to_be16((u16)cntrs.port_xmit_discards);
@@ -1623,7 +1623,7 @@ static int pma_get_portcounters_cong(struct ib_perf *pmp,
 	p->lli_ebor_errors = (cntrs.local_link_integrity_errors << 4) |
 		cntrs.excessive_buffer_overrun_errors;
 	if (cntrs.vl15_dropped > 0xFFFFUL)
-		p->vl15_dropped = cpu_to_be16(0xFFFF);
+		p->vl15_dropped = __constant_cpu_to_be16(0xFFFF);
 	else
 		p->vl15_dropped = cpu_to_be16((u16)cntrs.vl15_dropped);
 
diff --git a/drivers/infiniband/hw/qib/qib_mad.h b/drivers/infiniband/hw/qib/qib_mad.h
index a699ce7..6f6f245 100644
--- a/drivers/infiniband/hw/qib/qib_mad.h
+++ b/drivers/infiniband/hw/qib/qib_mad.h
@@ -32,10 +32,10 @@
  * SOFTWARE.
  */
 
-#define IB_SMP_UNSUP_VERSION    cpu_to_be16(0x0004)
-#define IB_SMP_UNSUP_METHOD     cpu_to_be16(0x0008)
-#define IB_SMP_UNSUP_METH_ATTR  cpu_to_be16(0x000C)
-#define IB_SMP_INVALID_FIELD    cpu_to_be16(0x001C)
+#define IB_SMP_UNSUP_VERSION    __constant_cpu_to_be16(0x0004)
+#define IB_SMP_UNSUP_METHOD     __constant_cpu_to_be16(0x0008)
+#define IB_SMP_UNSUP_METH_ATTR  __constant_cpu_to_be16(0x000C)
+#define IB_SMP_INVALID_FIELD    __constant_cpu_to_be16(0x001C)
 
 struct ib_node_info {
 	u8 base_version;
@@ -128,22 +128,22 @@ struct ib_mad_notice_attr {
 /*
  * Generic trap/notice producers
  */
-#define IB_NOTICE_PROD_CA		cpu_to_be16(1)
-#define IB_NOTICE_PROD_SWITCH		cpu_to_be16(2)
-#define IB_NOTICE_PROD_ROUTER		cpu_to_be16(3)
-#define IB_NOTICE_PROD_CLASS_MGR	cpu_to_be16(4)
+#define IB_NOTICE_PROD_CA		__constant_cpu_to_be16(1)
+#define IB_NOTICE_PROD_SWITCH		__constant_cpu_to_be16(2)
+#define IB_NOTICE_PROD_ROUTER		__constant_cpu_to_be16(3)
+#define IB_NOTICE_PROD_CLASS_MGR	__constant_cpu_to_be16(4)
 
 /*
  * Generic trap/notice numbers
  */
-#define IB_NOTICE_TRAP_LLI_THRESH	cpu_to_be16(129)
-#define IB_NOTICE_TRAP_EBO_THRESH	cpu_to_be16(130)
-#define IB_NOTICE_TRAP_FLOW_UPDATE	cpu_to_be16(131)
-#define IB_NOTICE_TRAP_CAP_MASK_CHG	cpu_to_be16(144)
-#define IB_NOTICE_TRAP_SYS_GUID_CHG	cpu_to_be16(145)
-#define IB_NOTICE_TRAP_BAD_MKEY		cpu_to_be16(256)
-#define IB_NOTICE_TRAP_BAD_PKEY		cpu_to_be16(257)
-#define IB_NOTICE_TRAP_BAD_QKEY		cpu_to_be16(258)
+#define IB_NOTICE_TRAP_LLI_THRESH	__constant_cpu_to_be16(129)
+#define IB_NOTICE_TRAP_EBO_THRESH	__constant_cpu_to_be16(130)
+#define IB_NOTICE_TRAP_FLOW_UPDATE	__constant_cpu_to_be16(131)
+#define IB_NOTICE_TRAP_CAP_MASK_CHG	__constant_cpu_to_be16(144)
+#define IB_NOTICE_TRAP_SYS_GUID_CHG	__constant_cpu_to_be16(145)
+#define IB_NOTICE_TRAP_BAD_MKEY		__constant_cpu_to_be16(256)
+#define IB_NOTICE_TRAP_BAD_PKEY		__constant_cpu_to_be16(257)
+#define IB_NOTICE_TRAP_BAD_QKEY		__constant_cpu_to_be16(258)
 
 /*
  * Repress trap/notice flags
@@ -183,17 +183,17 @@ struct ib_vl_weight_elem {
 /*
  * PMA class portinfo capability mask bits
  */
-#define IB_PMA_CLASS_CAP_ALLPORTSELECT  cpu_to_be16(1 << 8)
-#define IB_PMA_CLASS_CAP_EXT_WIDTH      cpu_to_be16(1 << 9)
-#define IB_PMA_CLASS_CAP_XMIT_WAIT      cpu_to_be16(1 << 12)
-
-#define IB_PMA_CLASS_PORT_INFO          cpu_to_be16(0x0001)
-#define IB_PMA_PORT_SAMPLES_CONTROL     cpu_to_be16(0x0010)
-#define IB_PMA_PORT_SAMPLES_RESULT      cpu_to_be16(0x0011)
-#define IB_PMA_PORT_COUNTERS            cpu_to_be16(0x0012)
-#define IB_PMA_PORT_COUNTERS_EXT        cpu_to_be16(0x001D)
-#define IB_PMA_PORT_SAMPLES_RESULT_EXT  cpu_to_be16(0x001E)
-#define IB_PMA_PORT_COUNTERS_CONG       cpu_to_be16(0xFF00)
+#define IB_PMA_CLASS_CAP_ALLPORTSELECT  __constant_cpu_to_be16(1 << 8)
+#define IB_PMA_CLASS_CAP_EXT_WIDTH      __constant_cpu_to_be16(1 << 9)
+#define IB_PMA_CLASS_CAP_XMIT_WAIT      __constant_cpu_to_be16(1 << 12)
+
+#define IB_PMA_CLASS_PORT_INFO          __constant_cpu_to_be16(0x0001)
+#define IB_PMA_PORT_SAMPLES_CONTROL     __constant_cpu_to_be16(0x0010)
+#define IB_PMA_PORT_SAMPLES_RESULT      __constant_cpu_to_be16(0x0011)
+#define IB_PMA_PORT_COUNTERS            __constant_cpu_to_be16(0x0012)
+#define IB_PMA_PORT_COUNTERS_EXT        __constant_cpu_to_be16(0x001D)
+#define IB_PMA_PORT_SAMPLES_RESULT_EXT  __constant_cpu_to_be16(0x001E)
+#define IB_PMA_PORT_COUNTERS_CONG       __constant_cpu_to_be16(0xFF00)
 
 struct ib_perf {
 	u8 base_version;
@@ -316,19 +316,19 @@ struct ib_pma_portcounters_cong {
 /* number of 4nsec cycles equaling 2secs */
 #define QIB_CONG_TIMER_PSINTERVAL               0x1DCD64EC
 
-#define IB_PMA_SEL_SYMBOL_ERROR                 cpu_to_be16(0x0001)
-#define IB_PMA_SEL_LINK_ERROR_RECOVERY          cpu_to_be16(0x0002)
-#define IB_PMA_SEL_LINK_DOWNED                  cpu_to_be16(0x0004)
-#define IB_PMA_SEL_PORT_RCV_ERRORS              cpu_to_be16(0x0008)
-#define IB_PMA_SEL_PORT_RCV_REMPHYS_ERRORS      cpu_to_be16(0x0010)
-#define IB_PMA_SEL_PORT_XMIT_DISCARDS           cpu_to_be16(0x0040)
-#define IB_PMA_SEL_LOCAL_LINK_INTEGRITY_ERRORS  cpu_to_be16(0x0200)
-#define IB_PMA_SEL_EXCESSIVE_BUFFER_OVERRUNS    cpu_to_be16(0x0400)
-#define IB_PMA_SEL_PORT_VL15_DROPPED            cpu_to_be16(0x0800)
-#define IB_PMA_SEL_PORT_XMIT_DATA               cpu_to_be16(0x1000)
-#define IB_PMA_SEL_PORT_RCV_DATA                cpu_to_be16(0x2000)
-#define IB_PMA_SEL_PORT_XMIT_PACKETS            cpu_to_be16(0x4000)
-#define IB_PMA_SEL_PORT_RCV_PACKETS             cpu_to_be16(0x8000)
+#define IB_PMA_SEL_SYMBOL_ERROR                 __constant_cpu_to_be16(0x0001)
+#define IB_PMA_SEL_LINK_ERROR_RECOVERY          __constant_cpu_to_be16(0x0002)
+#define IB_PMA_SEL_LINK_DOWNED                  __constant_cpu_to_be16(0x0004)
+#define IB_PMA_SEL_PORT_RCV_ERRORS              __constant_cpu_to_be16(0x0008)
+#define IB_PMA_SEL_PORT_RCV_REMPHYS_ERRORS      __constant_cpu_to_be16(0x0010)
+#define IB_PMA_SEL_PORT_XMIT_DISCARDS           __constant_cpu_to_be16(0x0040)
+#define IB_PMA_SEL_LOCAL_LINK_INTEGRITY_ERRORS  __constant_cpu_to_be16(0x0200)
+#define IB_PMA_SEL_EXCESSIVE_BUFFER_OVERRUNS    __constant_cpu_to_be16(0x0400)
+#define IB_PMA_SEL_PORT_VL15_DROPPED            __constant_cpu_to_be16(0x0800)
+#define IB_PMA_SEL_PORT_XMIT_DATA               __constant_cpu_to_be16(0x1000)
+#define IB_PMA_SEL_PORT_RCV_DATA                __constant_cpu_to_be16(0x2000)
+#define IB_PMA_SEL_PORT_XMIT_PACKETS            __constant_cpu_to_be16(0x4000)
+#define IB_PMA_SEL_PORT_RCV_PACKETS             __constant_cpu_to_be16(0x8000)
 
 #define IB_PMA_SEL_CONG_ALL                     0x01
 #define IB_PMA_SEL_CONG_PORT_DATA               0x02
@@ -350,14 +350,14 @@ struct ib_pma_portcounters_ext {
 	__be64 port_multicast_rcv_packets;
 } __attribute__ ((packed));
 
-#define IB_PMA_SELX_PORT_XMIT_DATA              cpu_to_be16(0x0001)
-#define IB_PMA_SELX_PORT_RCV_DATA               cpu_to_be16(0x0002)
-#define IB_PMA_SELX_PORT_XMIT_PACKETS           cpu_to_be16(0x0004)
-#define IB_PMA_SELX_PORT_RCV_PACKETS            cpu_to_be16(0x0008)
-#define IB_PMA_SELX_PORT_UNI_XMIT_PACKETS       cpu_to_be16(0x0010)
-#define IB_PMA_SELX_PORT_UNI_RCV_PACKETS        cpu_to_be16(0x0020)
-#define IB_PMA_SELX_PORT_MULTI_XMIT_PACKETS     cpu_to_be16(0x0040)
-#define IB_PMA_SELX_PORT_MULTI_RCV_PACKETS      cpu_to_be16(0x0080)
+#define IB_PMA_SELX_PORT_XMIT_DATA              __constant_cpu_to_be16(0x0001)
+#define IB_PMA_SELX_PORT_RCV_DATA               __constant_cpu_to_be16(0x0002)
+#define IB_PMA_SELX_PORT_XMIT_PACKETS           __constant_cpu_to_be16(0x0004)
+#define IB_PMA_SELX_PORT_RCV_PACKETS            __constant_cpu_to_be16(0x0008)
+#define IB_PMA_SELX_PORT_UNI_XMIT_PACKETS       __constant_cpu_to_be16(0x0010)
+#define IB_PMA_SELX_PORT_UNI_RCV_PACKETS        __constant_cpu_to_be16(0x0020)
+#define IB_PMA_SELX_PORT_MULTI_XMIT_PACKETS     __constant_cpu_to_be16(0x0040)
+#define IB_PMA_SELX_PORT_MULTI_RCV_PACKETS      __constant_cpu_to_be16(0x0080)
 
 /*
  * The PortSamplesControl.CounterMasks field is an array of 3 bit fields
@@ -366,9 +366,9 @@ struct ib_pma_portcounters_ext {
  */
 #define COUNTER_MASK(q, n) (q << ((9 - n) * 3))
 #define COUNTER_MASK0_9 \
-	cpu_to_be32(COUNTER_MASK(1, 0) | \
-		    COUNTER_MASK(1, 1) | \
-		    COUNTER_MASK(1, 2) | \
-		    COUNTER_MASK(1, 3) | \
-		    COUNTER_MASK(1, 4))
+	__constant_cpu_to_be32(COUNTER_MASK(1, 0) | \
+			       COUNTER_MASK(1, 1) | \
+			       COUNTER_MASK(1, 2) | \
+			       COUNTER_MASK(1, 3) | \
+			       COUNTER_MASK(1, 4))
 
diff --git a/drivers/infiniband/hw/qib/qib_mmap.c b/drivers/infiniband/hw/qib/qib_mmap.c
index ae15d38..4e37009 100644
--- a/drivers/infiniband/hw/qib/qib_mmap.c
+++ b/drivers/infiniband/hw/qib/qib_mmap.c
@@ -74,9 +74,40 @@ static void qib_vma_close(struct vm_area_struct *vma)
 	kref_put(&ip->ref, qib_release_mmap_info);
 }
 
+/*
+ * qib_vma_nopage - handle a VMA page fault.
+ */
+static struct page *qib_vma_nopage(struct vm_area_struct *vma,
+				     unsigned long address, int *type)
+{
+	struct qib_mmap_info *ip = vma->vm_private_data;
+	unsigned long offset = address - vma->vm_start;
+	struct page *page = NOPAGE_SIGBUS;
+	void *pageptr;
+
+	if (offset >= ip->size)
+		goto out; /* out of range */
+
+	/*
+	 * Convert the vmalloc address into a struct page.
+	 */
+	pageptr = (void *)(offset + ip->obj);
+	page = vmalloc_to_page(pageptr);
+	if (!page)
+		goto out;
+
+	/* Increment the reference count. */
+	get_page(page);
+	if (type)
+		*type = VM_FAULT_MINOR;
+out:
+	return page;
+}
+
 static struct vm_operations_struct qib_vm_ops = {
 	.open =     qib_vma_open,
 	.close =    qib_vma_close,
+	.nopage =   qib_vma_nopage,
 };
 
 /**
@@ -111,10 +142,10 @@ int qib_mmap(struct ib_ucontext *context, struct vm_area_struct *vma)
 		list_del_init(&ip->pending_mmaps);
 		spin_unlock_irq(&dev->pending_lock);
 
-		ret = remap_vmalloc_range(vma, ip->obj, 0);
-		if (ret)
-			goto done;
+		ret = 0;
+
 		vma->vm_ops = &qib_vm_ops;
+		vma->vm_flags |= VM_RESERVED | VM_DONTEXPAND;
 		vma->vm_private_data = ip;
 		qib_vma_open(vma);
 		goto done;
diff --git a/drivers/infiniband/hw/qib/qib_pcie.c b/drivers/infiniband/hw/qib/qib_pcie.c
index 96b4c50..6372ec7 100644
--- a/drivers/infiniband/hw/qib/qib_pcie.c
+++ b/drivers/infiniband/hw/qib/qib_pcie.c
@@ -124,7 +124,7 @@ int qib_pcie_init(struct pci_dev *pdev, const struct pci_device_id *ent)
 	pci_set_master(pdev);
 #ifdef CONFIG_PCIEAER
 	/* enable basic AER reporting.  Perhaps more later */
-	if (pci_find_ext_capability(pdev, PCI_EXT_CAP_ID_ERR)) {
+	if (pci_find_aer_capability(pdev)) {
 		ret = pci_enable_pcie_error_reporting(pdev);
 		if (ret)
 			qib_early_err(&pdev->dev,
diff --git a/drivers/infiniband/hw/qib/qib_qp.c b/drivers/infiniband/hw/qib/qib_qp.c
index 371af8a..177ad2f 100644
--- a/drivers/infiniband/hw/qib/qib_qp.c
+++ b/drivers/infiniband/hw/qib/qib_qp.c
@@ -37,6 +37,9 @@
 
 #include "qib.h"
 
+/* Undo OFED backport changes so we get the real cancel_delayed_work() */
+#undef cancel_delayed_work
+
 #define BITS_PER_PAGE           (PAGE_SIZE*BITS_PER_BYTE)
 #define BITS_PER_PAGE_MASK      (BITS_PER_PAGE-1)
 
@@ -680,7 +683,7 @@ int qib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 			spin_unlock(&qp->s_lock);
 			spin_unlock_irq(&qp->r_lock);
 			/* Stop the sending work queue and retry timer */
-			cancel_work_sync(&qp->s_work);
+			flush_workqueue(qib_wq);
 			del_timer_sync(&qp->s_timer);
 			wait_event(qp->wait_dma, !atomic_read(&qp->s_dma_busy));
 			if (qp->s_tx) {
@@ -1161,7 +1164,8 @@ int qib_destroy_qp(struct ib_qp *ibqp)
 		spin_unlock(&dev->pending_lock);
 		qp->s_flags &= ~(QIB_S_TIMER | QIB_S_ANY_WAIT);
 		spin_unlock_irq(&qp->s_lock);
-		cancel_work_sync(&qp->s_work);
+		cancel_delayed_work(&qp->s_work);
+		flush_workqueue(qib_wq);
 		del_timer_sync(&qp->s_timer);
 		wait_event(qp->wait_dma, !atomic_read(&qp->s_dma_busy));
 		if (qp->s_tx) {
diff --git a/drivers/infiniband/hw/qib/qib_rc.c b/drivers/infiniband/hw/qib/qib_rc.c
index 82e8d98..a11c74f 100644
--- a/drivers/infiniband/hw/qib/qib_rc.c
+++ b/drivers/infiniband/hw/qib/qib_rc.c
@@ -2060,7 +2060,7 @@ send_last:
 		/* Signal completion event if the solicited bit is set. */
 		qib_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,
 			     (ohdr->bth[0] &
-			      cpu_to_be32(IB_BTH_SOLICITED)) != 0);
+			      __constant_cpu_to_be32(IB_BTH_SOLICITED)) != 0);
 		break;
 
 	case OP(RDMA_WRITE_FIRST):
diff --git a/drivers/infiniband/hw/qib/qib_sdma.c b/drivers/infiniband/hw/qib/qib_sdma.c
index 878831c..3da10bb 100644
--- a/drivers/infiniband/hw/qib/qib_sdma.c
+++ b/drivers/infiniband/hw/qib/qib_sdma.c
@@ -591,7 +591,7 @@ retry:
 		dw = (len + 3) >> 2;
 		addr = dma_map_single(&ppd->dd->pcidev->dev, sge->vaddr,
 				      dw << 2, DMA_TO_DEVICE);
-		if (dma_mapping_error(&ppd->dd->pcidev->dev, addr))
+		if (dma_mapping_error(addr))
 			goto unmap;
 		sdmadesc[0] = 0;
 		make_sdma_desc(ppd, sdmadesc, (u64) addr, dw, dwoffset);
@@ -633,11 +633,11 @@ retry:
 	if (!tail)
 		descqp = &ppd->sdma_descq[ppd->sdma_descq_cnt].qw[0];
 	descqp -= 2;
-	descqp[0] |= cpu_to_le64(SDMA_DESC_LAST);
+	descqp[0] |= __constant_cpu_to_le64(SDMA_DESC_LAST);
 	if (tx->txreq.flags & QIB_SDMA_TXREQ_F_HEADTOHOST)
-		descqp[0] |= cpu_to_le64(SDMA_DESC_DMA_HEAD);
+		descqp[0] |= __constant_cpu_to_le64(SDMA_DESC_DMA_HEAD);
 	if (tx->txreq.flags & QIB_SDMA_TXREQ_F_INTREQ)
-		descqp[0] |= cpu_to_le64(SDMA_DESC_INTR);
+		descqp[0] |= __constant_cpu_to_le64(SDMA_DESC_INTR);
 
 	atomic_inc(&tx->qp->s_dma_busy);
 	tx->txreq.next_descq_idx = tail;
diff --git a/drivers/infiniband/hw/qib/qib_sysfs.c b/drivers/infiniband/hw/qib/qib_sysfs.c
index 747005a..5c9b2aa 100644
--- a/drivers/infiniband/hw/qib/qib_sysfs.c
+++ b/drivers/infiniband/hw/qib/qib_sysfs.c
@@ -262,18 +262,12 @@ static ssize_t qib_portattr_store(struct kobject *kobj,
 	return pattr->store(ppd, buf, len);
 }
 
-static void qib_port_release(struct kobject *kobj)
-{
-	/* nothing to do since memory is freed by qib_free_devdata() */
-}
-
 static struct sysfs_ops qib_port_ops = {
 	.show = qib_portattr_show,
 	.store = qib_portattr_store,
 };
 
 static struct kobj_type qib_port_ktype = {
-	.release = qib_port_release,
 	.sysfs_ops = &qib_port_ops,
 	.default_attrs = port_default_attributes
 };
@@ -345,7 +339,6 @@ static struct sysfs_ops qib_sl2vl_ops = {
 };
 
 static struct kobj_type qib_sl2vl_ktype = {
-	.release = qib_port_release,
 	.sysfs_ops = &qib_sl2vl_ops,
 	.default_attrs = sl2vl_default_attributes
 };
@@ -356,22 +349,20 @@ static struct kobj_type qib_sl2vl_ktype = {
 
 /*
  * Start of per-unit (or driver, in some cases, but replicated
- * per unit) functions (these get a device *)
+ * per unit) functions (these get a class_device *)
  */
-static ssize_t show_rev(struct device *device, struct device_attribute *attr,
-			char *buf)
+static ssize_t show_rev(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 
 	return sprintf(buf, "%x\n", dd_from_dev(dev)->minrev);
 }
 
-static ssize_t show_hca(struct device *device, struct device_attribute *attr,
-			char *buf)
+static ssize_t show_hca(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	int ret;
 
@@ -386,11 +377,10 @@ static const char *qp_type_str[] = {
 	"SMI", "GSI", "RC", "UC", "UD",
 };
 
-static ssize_t show_stats(struct device *device, struct device_attribute *attr,
-			  char *buf)
+static ssize_t show_stats(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	unsigned pidx;
 	unsigned i;
@@ -487,18 +477,16 @@ static ssize_t show_stats(struct device *device, struct device_attribute *attr,
 	return len;
 }
 
-static ssize_t show_version(struct device *device,
-			    struct device_attribute *attr, char *buf)
+static ssize_t show_version(struct class_device *cdev, char *buf)
 {
 	/* The string printed here is already newline-terminated. */
 	return scnprintf(buf, PAGE_SIZE, "%s", (char *)ib_qib_version);
 }
 
-static ssize_t show_boardversion(struct device *device,
-				 struct device_attribute *attr, char *buf)
+static ssize_t show_boardversion(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 
 	/* The string printed here is already newline-terminated. */
@@ -506,11 +494,10 @@ static ssize_t show_boardversion(struct device *device,
 }
 
 
-static ssize_t show_localbus_info(struct device *device,
-				  struct device_attribute *attr, char *buf)
+static ssize_t show_localbus_info(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 
 	/* The string printed here is already newline-terminated. */
@@ -518,11 +505,10 @@ static ssize_t show_localbus_info(struct device *device,
 }
 
 
-static ssize_t show_nctxts(struct device *device,
-			   struct device_attribute *attr, char *buf)
+static ssize_t show_nctxts(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 
 	/* Return the number of user ports (contexts) available. */
@@ -530,11 +516,10 @@ static ssize_t show_nctxts(struct device *device,
 		dd->first_user_ctxt);
 }
 
-static ssize_t show_serial(struct device *device,
-			   struct device_attribute *attr, char *buf)
+static ssize_t show_serial(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 
 	buf[sizeof dd->serial] = '\0';
@@ -543,12 +528,11 @@ static ssize_t show_serial(struct device *device,
 	return strlen(buf);
 }
 
-static ssize_t store_chip_reset(struct device *device,
-				struct device_attribute *attr, const char *buf,
+static ssize_t store_chip_reset(struct class_device *cdev, const char *buf,
 				size_t count)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	int ret;
 
@@ -562,11 +546,10 @@ bail:
 	return ret < 0 ? ret : count;
 }
 
-static ssize_t show_logged_errs(struct device *device,
-				struct device_attribute *attr, char *buf)
+static ssize_t show_logged_errs(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	int idx, count;
 
@@ -587,11 +570,10 @@ static ssize_t show_logged_errs(struct device *device,
 /*
  * Dump tempsense regs. in decimal, to ease shell-scripts.
  */
-static ssize_t show_tempsense(struct device *device,
-			      struct device_attribute *attr, char *buf)
+static ssize_t show_tempsense(struct class_device *cdev, char *buf)
 {
 	struct qib_ibdev *dev =
-		container_of(device, struct qib_ibdev, ibdev.dev);
+		container_of(cdev, struct qib_ibdev, ibdev.class_dev);
 	struct qib_devdata *dd = dd_from_dev(dev);
 	int ret;
 	int idx;
@@ -622,32 +604,32 @@ static ssize_t show_tempsense(struct device *device,
  */
 
 /* start of per-unit file structures and support code */
-static DEVICE_ATTR(hw_rev, S_IRUGO, show_rev, NULL);
-static DEVICE_ATTR(hca_type, S_IRUGO, show_hca, NULL);
-static DEVICE_ATTR(board_id, S_IRUGO, show_hca, NULL);
-static DEVICE_ATTR(stats, S_IRUGO, show_stats, NULL);
-static DEVICE_ATTR(version, S_IRUGO, show_version, NULL);
-static DEVICE_ATTR(nctxts, S_IRUGO, show_nctxts, NULL);
-static DEVICE_ATTR(serial, S_IRUGO, show_serial, NULL);
-static DEVICE_ATTR(boardversion, S_IRUGO, show_boardversion, NULL);
-static DEVICE_ATTR(logged_errors, S_IRUGO, show_logged_errs, NULL);
-static DEVICE_ATTR(tempsense, S_IRUGO, show_tempsense, NULL);
-static DEVICE_ATTR(localbus_info, S_IRUGO, show_localbus_info, NULL);
-static DEVICE_ATTR(chip_reset, S_IWUSR, NULL, store_chip_reset);
-
-static struct device_attribute *qib_attributes[] = {
-	&dev_attr_hw_rev,
-	&dev_attr_hca_type,
-	&dev_attr_board_id,
-	&dev_attr_stats,
-	&dev_attr_version,
-	&dev_attr_nctxts,
-	&dev_attr_serial,
-	&dev_attr_boardversion,
-	&dev_attr_logged_errors,
-	&dev_attr_tempsense,
-	&dev_attr_localbus_info,
-	&dev_attr_chip_reset,
+static CLASS_DEVICE_ATTR(hw_rev, S_IRUGO, show_rev, NULL);
+static CLASS_DEVICE_ATTR(hca_type, S_IRUGO, show_hca, NULL);
+static CLASS_DEVICE_ATTR(board_id, S_IRUGO, show_hca, NULL);
+static CLASS_DEVICE_ATTR(stats, S_IRUGO, show_stats, NULL);
+static CLASS_DEVICE_ATTR(version, S_IRUGO, show_version, NULL);
+static CLASS_DEVICE_ATTR(nctxts, S_IRUGO, show_nctxts, NULL);
+static CLASS_DEVICE_ATTR(serial, S_IRUGO, show_serial, NULL);
+static CLASS_DEVICE_ATTR(boardversion, S_IRUGO, show_boardversion, NULL);
+static CLASS_DEVICE_ATTR(logged_errors, S_IRUGO, show_logged_errs, NULL);
+static CLASS_DEVICE_ATTR(tempsense, S_IRUGO, show_tempsense, NULL);
+static CLASS_DEVICE_ATTR(localbus_info, S_IRUGO, show_localbus_info, NULL);
+static CLASS_DEVICE_ATTR(chip_reset, S_IWUSR, NULL, store_chip_reset);
+
+static struct class_device_attribute *qib_class_attributes[] = {
+	&class_device_attr_hw_rev,
+	&class_device_attr_hca_type,
+	&class_device_attr_board_id,
+	&class_device_attr_stats,
+	&class_device_attr_version,
+	&class_device_attr_nctxts,
+	&class_device_attr_serial,
+	&class_device_attr_boardversion,
+	&class_device_attr_logged_errors,
+	&class_device_attr_tempsense,
+	&class_device_attr_localbus_info,
+	&class_device_attr_chip_reset,
 };
 
 static int create_port_files(struct ib_device *ibdev, u8 port_num,
@@ -709,8 +691,9 @@ int qib_verbs_register_sysfs(struct qib_devdata *dd)
 	struct ib_device *dev = &dd->verbs_dev.ibdev;
 	int i, ret;
 
-	for (i = 0; i < ARRAY_SIZE(qib_attributes); ++i)
-		if (device_create_file(&dev->dev, qib_attributes[i])) {
+	for (i = 0; i < ARRAY_SIZE(qib_class_attributes); ++i)
+		if (class_device_create_file(&dev->class_dev,
+					     qib_class_attributes[i])) {
 			ret = 1;
 			goto bail;
 		}
diff --git a/drivers/infiniband/hw/qib/qib_trace.c b/drivers/infiniband/hw/qib/qib_trace.c
index 180ca20..d6ef643 100644
--- a/drivers/infiniband/hw/qib/qib_trace.c
+++ b/drivers/infiniband/hw/qib/qib_trace.c
@@ -39,7 +39,7 @@
 #include <linux/sched.h>
 #include <linux/wait.h>
 #include <linux/vmalloc.h>
-#include <linux/uaccess.h>
+#include <asm/uaccess.h>
 #include <linux/notifier.h>
 
 #include "qib.h"
@@ -245,7 +245,7 @@ struct qib_evt_file {
 
 struct evt_trace_device {
 	struct cdev *cdev;
-	struct device *device;
+	struct class_device *class_dev;
 };
 
 static int qib_trace_set_bufsize(const char *val, struct kernel_param *kp);
@@ -1318,7 +1318,7 @@ int __init qib_trace_init(void)
 	}
 
 	ret = qib_cdev_init(QIB_TRACE_MINOR, QIB_TRACE_FILE, &qib_trace_fops,
-			    &evt_dev.cdev, &evt_dev.device);
+			    &evt_dev.cdev, &evt_dev.class_dev);
 	if (ret)
 		goto bail_buf;
 
@@ -1341,7 +1341,7 @@ bail:
 void qib_trace_fini(void)
 {
 	if (qib_trace_buf) {
-		qib_cdev_cleanup(&evt_dev.cdev, &evt_dev.device);
+		qib_cdev_cleanup(&evt_dev.cdev, &evt_dev.class_dev);
 		atomic_notifier_chain_unregister(&panic_notifier_list,
 						 &qibtrace_panic_block);
 		qib_evt_buf_destroy(qib_trace_buf);
diff --git a/drivers/infiniband/hw/qib/qib_uc.c b/drivers/infiniband/hw/qib/qib_uc.c
index 5fc0fb0..167e5a6 100644
--- a/drivers/infiniband/hw/qib/qib_uc.c
+++ b/drivers/infiniband/hw/qib/qib_uc.c
@@ -419,7 +419,7 @@ last_imm:
 		/* Signal completion event if the solicited bit is set. */
 		qib_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,
 			     (ohdr->bth[0] &
-				cpu_to_be32(IB_BTH_SOLICITED)) != 0);
+				__constant_cpu_to_be32(IB_BTH_SOLICITED)) != 0);
 		break;
 
 	case OP(RDMA_WRITE_FIRST):
diff --git a/drivers/infiniband/hw/qib/qib_ud.c b/drivers/infiniband/hw/qib/qib_ud.c
index 4a51fd1..3e0ebd7 100644
--- a/drivers/infiniband/hw/qib/qib_ud.c
+++ b/drivers/infiniband/hw/qib/qib_ud.c
@@ -367,7 +367,7 @@ int qib_make_ud_req(struct qib_qp *qp)
 	 */
 	ohdr->bth[1] = ah_attr->dlid >= QIB_MULTICAST_LID_BASE &&
 		ah_attr->dlid != QIB_PERMISSIVE_LID ?
-		cpu_to_be32(QIB_MULTICAST_QPN) :
+		__constant_cpu_to_be32(QIB_MULTICAST_QPN) :
 		cpu_to_be32(wqe->wr.wr.ud.remote_qpn);
 	ohdr->bth[2] = cpu_to_be32(qp->s_next_psn++ & QIB_PSN_MASK);
 	/*
@@ -583,7 +583,7 @@ void qib_ud_rcv(struct qib_ibport *ibp, struct qib_ib_header *hdr,
 	/* Signal completion event if the solicited bit is set. */
 	qib_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,
 		     (ohdr->bth[0] &
-			cpu_to_be32(IB_BTH_SOLICITED)) != 0);
+			__constant_cpu_to_be32(IB_BTH_SOLICITED)) != 0);
 	return;
 
 drop:
diff --git a/drivers/infiniband/hw/qib/qib_user_sdma.c b/drivers/infiniband/hw/qib/qib_user_sdma.c
index f83031f..cb85e03 100644
--- a/drivers/infiniband/hw/qib/qib_user_sdma.c
+++ b/drivers/infiniband/hw/qib/qib_user_sdma.c
@@ -207,7 +207,7 @@ static int qib_user_sdma_coalesce(const struct qib_devdata *dd,
 
 	dma_addr = dma_map_page(&dd->pcidev->dev, page, 0, len,
 				DMA_TO_DEVICE);
-	if (dma_mapping_error(&dd->pcidev->dev, dma_addr)) {
+	if (dma_mapping_error(dma_addr)) {
 		ret = -ENOMEM;
 		goto free_unmap;
 	}
@@ -305,7 +305,7 @@ static int qib_user_sdma_pin_pages(const struct qib_devdata *dd,
 				     pages[j], 0, flen, DMA_TO_DEVICE);
 		unsigned long fofs = addr & ~PAGE_MASK;
 
-		if (dma_mapping_error(&dd->pcidev->dev, dma_addr)) {
+		if (dma_mapping_error(dma_addr)) {
 			ret = -ENOMEM;
 			goto done;
 		}
@@ -517,7 +517,7 @@ static int qib_user_sdma_queue_pkts(const struct qib_devdata *dd,
 		if (page) {
 			dma_addr = dma_map_page(&dd->pcidev->dev,
 						page, 0, len, DMA_TO_DEVICE);
-			if (dma_mapping_error(&dd->pcidev->dev, dma_addr)) {
+			if (dma_mapping_error(dma_addr)) {
 				ret = -ENOMEM;
 				goto free_pbc;
 			}
@@ -687,13 +687,13 @@ static inline __le64 qib_sdma_make_desc0(struct qib_pportdata *ppd,
 
 static inline __le64 qib_sdma_make_first_desc0(__le64 descq)
 {
-	return descq | cpu_to_le64(1ULL << 12);
+	return descq | __constant_cpu_to_le64(1ULL << 12);
 }
 
 static inline __le64 qib_sdma_make_last_desc0(__le64 descq)
 {
 					      /* last */  /* dma head */
-	return descq | cpu_to_le64(1ULL << 11 | 1ULL << 13);
+	return descq | __constant_cpu_to_le64(1ULL << 11 | 1ULL << 13);
 }
 
 static inline __le64 qib_sdma_make_desc1(u64 addr)
@@ -790,7 +790,7 @@ static int qib_user_sdma_push_pkts(struct qib_pportdata *ppd,
 		if (ofs > dd->piosize2kmax_dwords) {
 			for (i = 0; i < pkt->naddr; i++) {
 				ppd->sdma_descq[dtail].qw[0] |=
-					cpu_to_le64(1ULL << 14);
+					__constant_cpu_to_le64(1ULL << 14);
 				if (++dtail == ppd->sdma_descq_cnt)
 					dtail = 0;
 			}
diff --git a/drivers/infiniband/hw/qib/qib_verbs.c b/drivers/infiniband/hw/qib/qib_verbs.c
index 8706883..a27e0ba 100644
--- a/drivers/infiniband/hw/qib/qib_verbs.c
+++ b/drivers/infiniband/hw/qib/qib_verbs.c
@@ -1324,7 +1324,7 @@ static int qib_verbs_send_dma(struct qib_qp *qp, struct qib_ib_header *hdr,
 
 	tx->txreq.addr = dma_map_single(&dd->pcidev->dev, phdr,
 					tx->hdr_dwords << 2, DMA_TO_DEVICE);
-	if (dma_mapping_error(&dd->pcidev->dev, tx->txreq.addr))
+	if (dma_mapping_error(tx->txreq.addr))
 		goto map_err;
 	tx->align_buf = phdr;
 	tx->txreq.flags |= QIB_SDMA_TXREQ_F_FREEBUF;
@@ -1719,7 +1719,7 @@ static int qib_query_port(struct ib_device *ibdev, u8 port,
 	u16 lid = ppd->lid;
 
 	memset(props, 0, sizeof(*props));
-	props->lid = lid ? lid : be16_to_cpu(IB_LID_PERMISSIVE);
+	props->lid = lid ? lid : __constant_be16_to_cpu(IB_LID_PERMISSIVE);
 	props->lmc = ppd->lmc;
 	props->sm_lid = ibp->sm_lid;
 	props->sm_sl = ibp->sm_sl;
@@ -2093,7 +2093,7 @@ static void init_ibport(struct qib_pportdata *ppd)
 	spin_lock_init(&ibp->lock);
 	/* Set the prefix to the default value (see ch. 4.1.1) */
 	ibp->gid_prefix = IB_DEFAULT_GID_PREFIX;
-	ibp->sm_lid = be16_to_cpu(IB_LID_PERMISSIVE);
+	ibp->sm_lid = __constant_be16_to_cpu(IB_LID_PERMISSIVE);
 	ibp->port_cap_flags = IB_PORT_SYS_IMAGE_GUID_SUP |
 		IB_PORT_CLIENT_REG_SUP | IB_PORT_SL_MAP_SUP |
 		IB_PORT_TRAP_SUP | IB_PORT_AUTO_MIGR_SUP |
@@ -2260,6 +2260,7 @@ int qib_register_ib_device(struct qib_devdata *dd)
 	ibdev->phys_port_cnt = dd->num_pports;
 	ibdev->num_comp_vectors = 1;
 	ibdev->dma_device = &dd->pcidev->dev;
+	ibdev->class_dev.dev = ibdev->dma_device;
 	ibdev->query_device = qib_query_device;
 	ibdev->modify_device = qib_modify_device;
 	ibdev->query_port = qib_query_port;
diff --git a/drivers/infiniband/hw/qib/qib_verbs.h b/drivers/infiniband/hw/qib/qib_verbs.h
index 2b37481..9666cb5 100644
--- a/drivers/infiniband/hw/qib/qib_verbs.h
+++ b/drivers/infiniband/hw/qib/qib_verbs.h
@@ -94,13 +94,13 @@ struct qib_verbs_txreq;
 #define IB_PMA_SAMPLE_STATUS_RUNNING    0x02
 
 /* Mandatory IB performance counter select values. */
-#define IB_PMA_PORT_XMIT_DATA   cpu_to_be16(0x0001)
-#define IB_PMA_PORT_RCV_DATA    cpu_to_be16(0x0002)
-#define IB_PMA_PORT_XMIT_PKTS   cpu_to_be16(0x0003)
-#define IB_PMA_PORT_RCV_PKTS    cpu_to_be16(0x0004)
-#define IB_PMA_PORT_XMIT_WAIT   cpu_to_be16(0x0005)
+#define IB_PMA_PORT_XMIT_DATA   __constant_cpu_to_be16(0x0001)
+#define IB_PMA_PORT_RCV_DATA    __constant_cpu_to_be16(0x0002)
+#define IB_PMA_PORT_XMIT_PKTS   __constant_cpu_to_be16(0x0003)
+#define IB_PMA_PORT_RCV_PKTS    __constant_cpu_to_be16(0x0004)
+#define IB_PMA_PORT_XMIT_WAIT   __constant_cpu_to_be16(0x0005)
 
-#define QIB_VENDOR_IPG		cpu_to_be16(0xFFA0)
+#define QIB_VENDOR_IPG		__constant_cpu_to_be16(0xFFA0)
 
 #define IB_BTH_REQ_ACK		(1 << 31)
 #define IB_BTH_SOLICITED	(1 << 23)
diff --git a/drivers/infiniband/hw/qib/qib_verbs_mcast.c b/drivers/infiniband/hw/qib/qib_verbs_mcast.c
index dabb697..4edfe65 100644
--- a/drivers/infiniband/hw/qib/qib_verbs_mcast.c
+++ b/drivers/infiniband/hw/qib/qib_verbs_mcast.c
@@ -31,7 +31,8 @@
  * SOFTWARE.
  */
 
-#include <linux/rculist.h>
+#include <linux/list.h>
+#include <linux/rcupdate.h>
 
 #include "qib.h"
 
diff --git a/drivers/infiniband/hw/qib/qib_wc_pat.c b/drivers/infiniband/hw/qib/qib_wc_pat.c
index 5d137db..eb7cead 100644
--- a/drivers/infiniband/hw/qib/qib_wc_pat.c
+++ b/drivers/infiniband/hw/qib/qib_wc_pat.c
@@ -171,7 +171,7 @@ static int read_and_modify_pat(void)
 	preempt_disable();
 	rd_old_pat(&ret);
 	if (!ret)
-		smp_call_function(rd_old_pat, &ret, 1);
+		smp_call_function(rd_old_pat, &ret, 1, 1);
 	if (ret)
 		goto out;
 
@@ -182,7 +182,7 @@ static int read_and_modify_pat(void)
 	if (ret)
 		goto out;
 
-	smp_call_function(wr_new_pat, &ret, 1);
+	smp_call_function(wr_new_pat, &ret, 1, 1);
 	BUG_ON(ret); /* have inconsistent PAT state */
 out:
 	preempt_enable();
@@ -196,7 +196,7 @@ static int restore_pat(void)
 	preempt_disable();
 	wr_old_pat(&ret);
 	if (!ret) {
-		smp_call_function(wr_old_pat, &ret, 1);
+		smp_call_function(wr_old_pat, &ret, 1, 1);
 		BUG_ON(ret); /* have inconsistent PAT state */
 	}
 
@@ -206,7 +206,7 @@ static int restore_pat(void)
 
 int qib_enable_wc_pat(void)
 {
-	struct cpuinfo_x86 *c = &cpu_data(0);
+	struct cpuinfo_x86 *c = &(cpu_data)[0];
 	int ret;
 
 	if (wc_enabled)
@@ -246,6 +246,11 @@ pgprot_t pgprot_writecombine(pgprot_t _prot)
 		pgprot_noncached(_prot);
 }
 
+void __iomem *ioremap_wc(unsigned long phys_addr, unsigned long size)
+{
+	return __ioremap(phys_addr, size, QIB_WC_FLAGS);
+}
+
 int qib_wc_pat_enabled(void)
 {
 	return wc_enabled;
@@ -261,6 +266,11 @@ pgprot_t pgprot_writecombine(pgprot_t _prot)
 	return pgprot_noncached(_prot);
 }
 
+void __iomem *ioremap_wc(unsigned long phys_addr, unsigned long size)
+{
+	return ioremap_nocache(phys_addr, size);
+}
+
 int qib_wc_pat_enabled(void)
 {
 	return 0;
diff --git a/drivers/infiniband/hw/qib/qib_wc_pat.h b/drivers/infiniband/hw/qib/qib_wc_pat.h
index 998029d..d016f4e 100644
--- a/drivers/infiniband/hw/qib/qib_wc_pat.h
+++ b/drivers/infiniband/hw/qib/qib_wc_pat.h
@@ -44,5 +44,6 @@ int qib_enable_wc_pat(void);
 void qib_disable_wc_pat(void);
 int qib_wc_pat_enabled(void);
 pgprot_t pgprot_writecombine(pgprot_t _prot);
+void __iomem *ioremap_wc(unsigned long phys_addr, unsigned long size);
 
 #endif
